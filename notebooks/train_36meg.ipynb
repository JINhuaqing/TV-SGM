{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadabb59",
   "metadata": {},
   "source": [
    "Here, I test whether my LSTM net works or not to estimate SGM parameters \n",
    "\n",
    "Now I run the real data from Parul (Apr 2, 2023)\n",
    "\n",
    "Convert to dB Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77566fcf-6190-41eb-8168-972aeea4fcad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:43.398325Z",
     "iopub.status.busy": "2024-01-05T02:56:43.397580Z",
     "iopub.status.idle": "2024-01-05T02:56:43.420510Z",
     "shell.execute_reply": "2024-01-05T02:56:43.419145Z",
     "shell.execute_reply.started": "2024-01-05T02:56:43.398277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_PYTHON_SCRIPT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9942dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:37:57.771920Z",
     "start_time": "2023-04-04T17:37:56.085736Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:43.421933Z",
     "iopub.status.busy": "2024-01-05T02:56:43.421503Z",
     "iopub.status.idle": "2024-01-05T02:56:43.564565Z",
     "shell.execute_reply": "2024-01-05T02:56:43.563611Z",
     "shell.execute_reply.started": "2024-01-05T02:56:43.421895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad09a305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:03.434191Z",
     "start_time": "2023-04-04T17:37:58.883670Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:43.566197Z",
     "iopub.status.busy": "2024-01-05T02:56:43.565876Z",
     "iopub.status.idle": "2024-01-05T02:56:44.366257Z",
     "shell.execute_reply": "2024-01-05T02:56:44.365239Z",
     "shell.execute_reply.started": "2024-01-05T02:56:43.566180Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import trange, tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209e7331-f7e7-4423-9c3e-8e29bd17c091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:44.367349Z",
     "iopub.status.busy": "2024-01-05T02:56:44.367026Z",
     "iopub.status.idle": "2024-01-05T02:56:44.384464Z",
     "shell.execute_reply": "2024-01-05T02:56:44.383977Z",
     "shell.execute_reply.started": "2024-01-05T02:56:44.367333Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 0,1, 2, 3, be careful about the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0924abca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:12.656580Z",
     "start_time": "2023-04-04T17:38:12.479288Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:44.385474Z",
     "iopub.status.busy": "2024-01-05T02:56:44.385229Z",
     "iopub.status.idle": "2024-01-05T02:56:45.656766Z",
     "shell.execute_reply": "2024-01-05T02:56:45.655897Z",
     "shell.execute_reply.started": "2024-01-05T02:56:44.385458Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.reparam import theta2raw_torch, raw2theta_torch, raw2theta_np\n",
    "from spectrome import Brain\n",
    "from sgm.sgm import SGM\n",
    "from utils.stable import paras_stable_check\n",
    "from utils.misc import save_pkl, save_pkl_dict2folder, load_pkl, load_pkl_folder2dict, delta_time\n",
    "from models.lstm import LSTM_SGM\n",
    "from models.model_utils import weights_init\n",
    "from models.loss import  weighted_mse_loss, reg_R_loss, lin_R_loss, lin_R_fn, reg_R_fn\n",
    "from utils.standardize import std_mat, std_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dade48c-e771-4425-b732-c465e8f78914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:45.658307Z",
     "iopub.status.busy": "2024-01-05T02:56:45.657866Z",
     "iopub.status.idle": "2024-01-05T02:56:45.683296Z",
     "shell.execute_reply": "2024-01-05T02:56:45.682827Z",
     "shell.execute_reply.started": "2024-01-05T02:56:45.658278Z"
    }
   },
   "outputs": [],
   "source": [
    "# pkgs for pytorch ( Mar 27, 2023) \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "df_dtype = torch.float32\n",
    "torch.set_default_dtype(df_dtype)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    torch.set_default_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7d4e70-0791-468a-bdc6-d2ce1a7feb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:45.684025Z",
     "iopub.status.busy": "2024-01-05T02:56:45.683845Z",
     "iopub.status.idle": "2024-01-05T02:56:45.704817Z",
     "shell.execute_reply": "2024-01-05T02:56:45.704367Z",
     "shell.execute_reply.started": "2024-01-05T02:56:45.684010Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "import random\n",
    "random.seed(seed)\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cd127-34b0-4132-a0a3-efa7f5c514cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7a4da6",
   "metadata": {},
   "source": [
    "# Data, fn and paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521836de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:17.218490Z",
     "start_time": "2023-04-04T17:38:13.493691Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:45.705568Z",
     "iopub.status.busy": "2024-01-05T02:56:45.705403Z",
     "iopub.status.idle": "2024-01-05T02:56:49.087373Z",
     "shell.execute_reply": "2024-01-05T02:56:49.086458Z",
     "shell.execute_reply.started": "2024-01-05T02:56:45.705555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "fils = list(DATA_ROOT.glob(\"*s100tp.nc\")) # 300/150\n",
    "file2read = netCDF4.Dataset(fils[0], 'r')\n",
    "psd_all_full = np.array(file2read.variables[\"__xarray_dataarray_variable__\"][:])\n",
    "psd_all_full = 10 * np.log10(psd_all_full) # to dB scale, \n",
    "# make it num_sub x num_roi x num_freqs x num_ts\n",
    "psd_all_full = psd_all_full.transpose(3, 0, 1, 2)\n",
    "time_points = np.array(file2read.variables[\"timepoints\"][:])\n",
    "freqs = np.array(file2read.variables[\"frequencies\"][:])\n",
    "ROIs_order = np.array(file2read.variables[\"regionx\"][:])\n",
    "file2read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa1dd84-5fbf-4746-960f-ea8ff1e2c490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T18:11:49.208224Z",
     "iopub.status.busy": "2024-01-05T18:11:49.207571Z",
     "iopub.status.idle": "2024-01-05T18:11:49.328829Z",
     "shell.execute_reply": "2024-01-05T18:11:49.327705Z",
     "shell.execute_reply.started": "2024-01-05T18:11:49.208178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7244898 ,  3.83673469,  4.94897959,  6.06122449,  7.17346939,\n",
       "        8.28571429,  9.39795918, 10.51020408, 11.62244898, 12.73469388,\n",
       "       13.84693878, 14.95918367, 16.07142857, 17.18367347, 18.29591837,\n",
       "       19.40816327, 20.52040816, 21.63265306, 22.74489796, 23.85714286,\n",
       "       24.96938776, 26.08163265, 27.19387755, 28.30612245, 29.41836735,\n",
       "       30.53061224, 31.64285714, 32.75510204, 33.86734694, 34.97959184,\n",
       "       36.09183673, 37.20408163, 38.31632653, 39.42857143, 40.54081633,\n",
       "       41.65306122, 42.76530612, 43.87755102, 44.98979592])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52938202-9ebb-4335-aacf-68d53a59a00a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.090524Z",
     "iopub.status.busy": "2024-01-05T02:56:49.089952Z",
     "iopub.status.idle": "2024-01-05T02:56:49.117404Z",
     "shell.execute_reply": "2024-01-05T02:56:49.116963Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.090490Z"
    }
   },
   "outputs": [],
   "source": [
    "#I remove the first and last time pts\n",
    "rm_lim = 5\n",
    "if rm_lim > 0:\n",
    "    psd_all_full = psd_all_full[:, :, :, rm_lim:-rm_lim]\n",
    "    time_points = time_points[rm_lim:-rm_lim];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180f0d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:18.614858Z",
     "start_time": "2023-04-04T17:38:18.509968Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.118126Z",
     "iopub.status.busy": "2024-01-05T02:56:49.117958Z",
     "iopub.status.idle": "2024-01-05T02:56:49.150292Z",
     "shell.execute_reply": "2024-01-05T02:56:49.149838Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.118111Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Connectome\n",
    "brain = Brain.Brain()\n",
    "brain.add_connectome(DATA_ROOT)\n",
    "brain.reorder_connectome(brain.connectome, brain.distance_matrix)\n",
    "brain.bi_symmetric_c()\n",
    "brain.reduce_extreme_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85a7c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:22.084241Z",
     "start_time": "2023-04-04T17:38:22.076317Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.151077Z",
     "iopub.status.busy": "2024-01-05T02:56:49.150897Z",
     "iopub.status.idle": "2024-01-05T02:56:49.168388Z",
     "shell.execute_reply": "2024-01-05T02:56:49.167967Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.151062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some constant parameters for this file\n",
    "paras = edict()\n",
    "\n",
    "## I reorder them in an alphabetical order and I change tauC to tauG (Mar 27, 2023)\n",
    "## the orginal order is taue, taui, tauC, speed, alpha, gii, gei\n",
    "## paras.par_low = np.asarray([0.005,0.005,0.005,5, 0.1,0.001,0.001])\n",
    "## paras.par_high = np.asarray([0.03, 0.20, 0.03,20,  1,    2,  0.7])\n",
    "##\n",
    "\n",
    "# alpha, gei, gii, taue, tauG, taui, speed \n",
    "paras.par_low = np.array([0.1, 0.001,0.001, 0.005, 0.005, 0.005, 5])\n",
    "paras.par_high = np.asarray([1, 0.7, 2, 0.03, 0.03, 0.20, 20])\n",
    "paras.prior_bds = np.array([paras.par_low, paras.par_high]).T\n",
    "paras.names = [\"alpha\", \"gei\", \"gii\", \"Taue\", \"TauG\", \"Taui\", \"Speed\"]\n",
    "\n",
    "paras.C = brain.reducedConnectome\n",
    "paras.D = brain.distance_matrix\n",
    "paras.freqs = freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ce16ba",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49a3544-8248-45e0-b006-4464dbaaf09f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:36.267294Z",
     "start_time": "2023-04-04T17:38:35.514912Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.168972Z",
     "iopub.status.busy": "2024-01-05T02:56:49.168831Z",
     "iopub.status.idle": "2024-01-05T02:56:49.247811Z",
     "shell.execute_reply": "2024-01-05T02:56:49.246973Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.168961Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net/freqs.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net/loss.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net/loss_test.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net/model.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net/paras.pkl\n"
     ]
    }
   ],
   "source": [
    "trained_model = load_pkl_folder2dict(RES_ROOT/\"SGM_net\", excluding=['opt*'])\n",
    "sgm_net = trained_model.model;\n",
    "sgm_net.to(dtype=df_dtype);\n",
    "sgm_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d507dc44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:47.060338Z",
     "start_time": "2023-04-04T17:38:46.969000Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.249166Z",
     "iopub.status.busy": "2024-01-05T02:56:49.248827Z",
     "iopub.status.idle": "2024-01-05T02:56:49.354305Z",
     "shell.execute_reply": "2024-01-05T02:56:49.353842Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.249142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to generate training sample (Apr 1, 2023)\n",
    "def random_choice(n, batchsize=1, len_seg=None):\n",
    "    \"\"\"Randomly select the lower and upper bound of the segment\n",
    "        args:\n",
    "            n: len of the total time series\n",
    "    \"\"\"\n",
    "    if len_seg is None:\n",
    "        len_seg = torch.randint(low=10, high=100, size=(1, ))\n",
    "    up_bd = torch.randint(low=len_seg.item(), high=n, size=(batchsize, ))\n",
    "    low_bd = up_bd - len_seg\n",
    "    return low_bd, up_bd\n",
    "\n",
    "\n",
    "def random_samples_rnn(X, Y=None, batchsize=1, \n",
    "                       bds=None, \n",
    "                       is_std=True, \n",
    "                       theta2raw_fn=None):\n",
    "    \"\"\"Randomly select a sample from the whole segment\n",
    "        args:\n",
    "            X: PSD, num_seq x 68 x nfreq or \n",
    "               PSD, num_sub x num_seq x 68 x nfreq\n",
    "            Y: params, num x 7, in original sgm scale\n",
    "        return:\n",
    "            X_seqs: len_seq x batchsize x num_fs\n",
    "            Y_seqs: len_seq x batchsize x 7\n",
    "            \n",
    "    \"\"\"\n",
    "    if X.ndim == 4:\n",
    "        # if multiple subjects, pick up a subject\n",
    "        num_sub = X.shape[0]\n",
    "        sub_idx = np.random.randint(low=0, high=num_sub)\n",
    "        X = X[sub_idx]\n",
    "        \n",
    "    if not isinstance(X, torch.Tensor):\n",
    "        X = torch.tensor(X)\n",
    "    if is_std:\n",
    "        #X = X/X.std(axis=(1, 2), keepdims=True)\n",
    "        # Let std for each ROI and each data\n",
    "        X = (X-X.mean(axis=2, keepdims=True))/X.std(axis=2, keepdims=True)\n",
    "    if Y is not None:\n",
    "        if not isinstance(Y, torch.Tensor):\n",
    "            Y = torch.tensor(Y)\n",
    "        if theta2raw_fn: \n",
    "            Y = theta2raw_fn(Y)\n",
    "    if bds is None:\n",
    "        low_bds, up_bds = random_choice(len(X), batchsize)\n",
    "    else:\n",
    "        low_bds, up_bds = bds\n",
    "\n",
    "    X = X.flatten(1)\n",
    "    X_seqs = []\n",
    "    Y_seqs = []\n",
    "    for low_bd, up_bd in zip(low_bds, up_bds):\n",
    "        X_seq = X[low_bd:up_bd, :].unsqueeze(1)\n",
    "        X_seqs.append(X_seq)\n",
    "        if Y is not None:\n",
    "            Y_seq = Y[low_bd:up_bd].unsqueeze(1)\n",
    "            Y_seqs.append(Y_seq)\n",
    "    if Y is not None:\n",
    "        return torch.cat(X_seqs, dim=1), torch.cat(Y_seqs, dim=1)\n",
    "    else:\n",
    "        return torch.cat(X_seqs, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54267b97-31f7-40bc-b85a-2b2115e4d290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.355419Z",
     "iopub.status.busy": "2024-01-05T02:56:49.355149Z",
     "iopub.status.idle": "2024-01-05T02:56:49.377031Z",
     "shell.execute_reply": "2024-01-05T02:56:49.376686Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.355404Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _evaluate(all_data):\n",
    "    num_sub, len_seq, _, _ = all_data.shape\n",
    "    all_data_raw = torch.tensor(all_data, dtype=df_dtype).transpose(1, 0)\n",
    "    all_data_input = (all_data_raw - all_data_raw.mean(axis=-1, keepdims=True))/all_data_raw.std(axis=-1, keepdims=True);\n",
    "    all_data_input = all_data_input.flatten(2);\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Y_pred = rnn(all_data_input);\n",
    "        X_pred = sgm_net(Y_pred.flatten(0, 1));\n",
    "    corrs = reg_R_fn(all_data_raw.flatten(0, 1), X_pred);\n",
    "    corrs = corrs.reshape(len_seq, num_sub, -1).transpose(1, 0)\n",
    "    return corrs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b012fbd2-5fe0-421e-86a8-b766a004948b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.377653Z",
     "iopub.status.busy": "2024-01-05T02:56:49.377501Z",
     "iopub.status.idle": "2024-01-05T02:56:49.547571Z",
     "shell.execute_reply": "2024-01-05T02:56:49.547106Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.377641Z"
    }
   },
   "outputs": [],
   "source": [
    "paras_rnn = edict()\n",
    "# batchsize is not in fact used.\n",
    "paras_rnn.batchsize = 128\n",
    "paras_rnn.niter = 1000 #!!!! 500\n",
    "paras_rnn.loss_out = 1\n",
    "paras_rnn.eval_out = 20\n",
    "paras_rnn.clip = 1 # from \n",
    "paras_rnn.lr_step = 300 #!!!! 10\n",
    "paras_rnn.gamma = 0.5 #!!!! 0.9\n",
    "paras_rnn.lr = 2e-4 \n",
    "\n",
    "paras_rnn.k = 1\n",
    "paras_rnn.hidden_dim = int(1024/4)\n",
    "paras_rnn.output_dim = 7\n",
    "paras_rnn.input_dim = 68*len(paras.freqs)\n",
    "paras_rnn.is_bidirectional = False#!!!!False\n",
    "paras_rnn.unstable_pen = 10000 # Whether to filter out the unstable sps or not, if 0 not, if large number, yes\n",
    "paras_rnn.loss_name = \"wmse\" # linR, corr, wmse or mse\n",
    "#paras.names = [\"alpha\", \"gei\", \"gii\", \"Taue\", \"TauG\", \"Taui\", \"Speed\"]\n",
    "# 1 dynamic, 0 static\n",
    "paras_rnn.dy_mask = [1, 1, 1, 1, 1, 1, 0] \n",
    "stat_part = \"_\".join(np.array(paras.names)[np.array(paras_rnn.dy_mask)==0][:-1])\n",
    "if len(stat_part) > 0:\n",
    "    folder_name = f\"LSTM_simu_net_36meg_{paras_rnn.loss_name}_{stat_part}\";\n",
    "else:\n",
    "    folder_name = f\"LSTM_simu_net_36meg_{paras_rnn.loss_name}\";\n",
    "paras_rnn.save_dir = RES_ROOT/folder_name\n",
    "\n",
    "\n",
    "psd_all = psd_all_full\n",
    "#  all_data is the real data, should be num_sub x len_seq x nrois x nfreqs\n",
    "#  or len_seq x nrois x nfreqs\n",
    "all_data = psd_all.transpose(0, 3, 1, 2)\n",
    "\n",
    "all_data_raw = torch.tensor(all_data, dtype=df_dtype).transpose(1, 0)\n",
    "all_data_input = (all_data_raw - all_data_raw.mean(axis=-1, keepdims=True))/all_data_raw.std(axis=-1, keepdims=True);\n",
    "all_data_input = all_data_input.flatten(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0257178-3d7c-4b84-b40e-1fbf16107d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.548434Z",
     "iopub.status.busy": "2024-01-05T02:56:49.548154Z",
     "iopub.status.idle": "2024-01-05T02:56:49.596443Z",
     "shell.execute_reply": "2024-01-05T02:56:49.596073Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.548419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.ExponentialLR at 0x7f1169652a30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = LSTM_SGM(input_dim=paras_rnn.input_dim, \n",
    "               hidden_dim=paras_rnn.hidden_dim, \n",
    "               output_dim=paras_rnn.output_dim, \n",
    "               is_bidirectional=paras_rnn.is_bidirectional, \n",
    "               prior_bds=torch.tensor(paras.prior_bds, dtype=df_dtype), \n",
    "               k = paras_rnn.k, \n",
    "               dy_mask = paras_rnn.dy_mask\n",
    ")\n",
    "rnn.apply(weights_init)\n",
    "rnn.to(dtype=df_dtype);\n",
    "if paras_rnn.loss_name.startswith(\"corr\"):\n",
    "    loss_fn = reg_R_loss\n",
    "elif paras_rnn.loss_name.startswith(\"linR\"):\n",
    "    loss_fn = lin_R_loss\n",
    "elif paras_rnn.loss_name.startswith(\"wmse\"):\n",
    "    loss_fn = weighted_mse_loss\n",
    "elif paras_rnn.loss_name.startswith(\"mse\"):\n",
    "    loss_fn = nn.MSELoss()\n",
    "else:\n",
    "    raise KeyError(\"No such loss\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnn.parameters(), lr=paras_rnn.lr, weight_decay=0)\n",
    "scheduler = ExponentialLR(optimizer, gamma=paras_rnn.gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c16bc60-34b0-4e7d-a640-30dc5ee454de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T02:56:49.597221Z",
     "iopub.status.busy": "2024-01-05T02:56:49.596979Z",
     "iopub.status.idle": "2024-01-05T03:25:13.815542Z",
     "shell.execute_reply": "2024-01-05T03:25:13.815079Z",
     "shell.execute_reply.started": "2024-01-05T02:56:49.597207Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iter 1/1000, the losses are 2.83012 (train). The time used is 1.875s. \n",
      "At iter 2/1000, the losses are 2.71379 (train). The time used is 1.805s. \n",
      "At iter 3/1000, the losses are 2.67381 (train). The time used is 1.893s. \n",
      "At iter 4/1000, the losses are 2.63547 (train). The time used is 1.811s. \n",
      "At iter 5/1000, the losses are 2.57832 (train). The time used is 1.879s. \n",
      "At iter 6/1000, the losses are 2.50872 (train). The time used is 1.786s. \n",
      "At iter 7/1000, the losses are 2.44638 (train). The time used is 1.786s. \n",
      "At iter 8/1000, the losses are 2.38293 (train). The time used is 1.821s. \n",
      "At iter 9/1000, the losses are 2.32352 (train). The time used is 1.780s. \n",
      "At iter 10/1000, the losses are 2.25683 (train). The time used is 1.794s. \n",
      "At iter 11/1000, the losses are 2.19898 (train). The time used is 1.812s. \n",
      "At iter 12/1000, the losses are 2.14877 (train). The time used is 1.792s. \n",
      "At iter 13/1000, the losses are 2.10108 (train). The time used is 1.812s. \n",
      "At iter 14/1000, the losses are 2.07552 (train). The time used is 1.487s. \n",
      "At iter 15/1000, the losses are 2.05080 (train). The time used is 1.520s. \n",
      "At iter 16/1000, the losses are 2.02667 (train). The time used is 1.479s. \n",
      "At iter 17/1000, the losses are 2.00140 (train). The time used is 1.472s. \n",
      "At iter 18/1000, the losses are 1.97473 (train). The time used is 1.537s. \n",
      "At iter 19/1000, the losses are 1.94564 (train). The time used is 1.547s. \n",
      "At iter 20/1000, the losses are 1.91584 (train). The time used is 1.579s. \n",
      "====================================================================================================\n",
      "At iter 20/1000, the losses on all data are 0.82333. The time used is 0.625s. \n",
      "====================================================================================================\n",
      "At iter 21/1000, the losses are 1.88867 (train). The time used is 1.756s. \n",
      "At iter 22/1000, the losses are 1.85786 (train). The time used is 1.839s. \n",
      "At iter 23/1000, the losses are 1.82680 (train). The time used is 1.942s. \n",
      "At iter 24/1000, the losses are 1.79495 (train). The time used is 1.827s. \n",
      "At iter 25/1000, the losses are 1.77190 (train). The time used is 1.828s. \n",
      "At iter 26/1000, the losses are 1.76489 (train). The time used is 1.840s. \n",
      "At iter 27/1000, the losses are 1.75936 (train). The time used is 1.829s. \n",
      "At iter 28/1000, the losses are 1.74549 (train). The time used is 1.832s. \n",
      "At iter 29/1000, the losses are 1.72484 (train). The time used is 1.839s. \n",
      "At iter 30/1000, the losses are 1.70711 (train). The time used is 1.812s. \n",
      "At iter 31/1000, the losses are 1.70073 (train). The time used is 1.879s. \n",
      "At iter 32/1000, the losses are 1.69722 (train). The time used is 1.771s. \n",
      "At iter 33/1000, the losses are 1.69194 (train). The time used is 1.796s. \n",
      "At iter 34/1000, the losses are 1.68697 (train). The time used is 1.807s. \n",
      "At iter 35/1000, the losses are 1.68069 (train). The time used is 1.786s. \n",
      "At iter 36/1000, the losses are 1.67746 (train). The time used is 1.776s. \n",
      "At iter 37/1000, the losses are 1.67484 (train). The time used is 1.801s. \n",
      "At iter 38/1000, the losses are 1.67334 (train). The time used is 1.846s. \n",
      "At iter 39/1000, the losses are 1.67096 (train). The time used is 1.794s. \n",
      "At iter 40/1000, the losses are 1.66960 (train). The time used is 1.864s. \n",
      "====================================================================================================\n",
      "At iter 40/1000, the losses on all data are 0.83087. The time used is 0.540s. \n",
      "====================================================================================================\n",
      "At iter 41/1000, the losses are 1.66725 (train). The time used is 1.513s. \n",
      "At iter 42/1000, the losses are 1.66487 (train). The time used is 1.475s. \n",
      "At iter 43/1000, the losses are 1.66225 (train). The time used is 1.470s. \n",
      "At iter 44/1000, the losses are 1.65979 (train). The time used is 1.483s. \n",
      "At iter 45/1000, the losses are 1.65805 (train). The time used is 1.469s. \n",
      "At iter 46/1000, the losses are 1.65621 (train). The time used is 1.704s. \n",
      "At iter 47/1000, the losses are 1.65484 (train). The time used is 1.802s. \n",
      "At iter 48/1000, the losses are 1.65314 (train). The time used is 1.841s. \n",
      "At iter 49/1000, the losses are 1.65078 (train). The time used is 1.574s. \n",
      "At iter 50/1000, the losses are 1.64848 (train). The time used is 1.538s. \n",
      "At iter 51/1000, the losses are 1.64624 (train). The time used is 1.564s. \n",
      "At iter 52/1000, the losses are 1.64432 (train). The time used is 1.731s. \n",
      "At iter 53/1000, the losses are 1.64275 (train). The time used is 1.813s. \n",
      "At iter 54/1000, the losses are 1.64052 (train). The time used is 1.791s. \n",
      "At iter 55/1000, the losses are 1.63794 (train). The time used is 1.800s. \n",
      "At iter 56/1000, the losses are 1.63562 (train). The time used is 1.770s. \n",
      "At iter 57/1000, the losses are 1.63348 (train). The time used is 1.759s. \n",
      "At iter 58/1000, the losses are 1.63128 (train). The time used is 1.829s. \n",
      "At iter 59/1000, the losses are 1.62916 (train). The time used is 1.831s. \n",
      "At iter 60/1000, the losses are 1.62684 (train). The time used is 1.796s. \n",
      "====================================================================================================\n",
      "At iter 60/1000, the losses on all data are 0.83452. The time used is 0.649s. \n",
      "====================================================================================================\n",
      "At iter 61/1000, the losses are 1.62441 (train). The time used is 1.702s. \n",
      "At iter 62/1000, the losses are 1.62218 (train). The time used is 1.498s. \n",
      "At iter 63/1000, the losses are 1.61994 (train). The time used is 1.486s. \n",
      "At iter 64/1000, the losses are 1.61750 (train). The time used is 1.542s. \n",
      "At iter 65/1000, the losses are 1.61506 (train). The time used is 1.486s. \n",
      "At iter 66/1000, the losses are 1.61274 (train). The time used is 1.466s. \n",
      "At iter 67/1000, the losses are 1.61046 (train). The time used is 1.604s. \n",
      "At iter 68/1000, the losses are 1.60814 (train). The time used is 1.849s. \n",
      "At iter 69/1000, the losses are 1.60603 (train). The time used is 1.828s. \n",
      "At iter 70/1000, the losses are 1.60411 (train). The time used is 1.805s. \n",
      "At iter 71/1000, the losses are 1.60225 (train). The time used is 1.881s. \n",
      "At iter 72/1000, the losses are 1.60073 (train). The time used is 1.789s. \n",
      "At iter 73/1000, the losses are 1.59949 (train). The time used is 1.879s. \n",
      "At iter 74/1000, the losses are 1.59875 (train). The time used is 1.790s. \n",
      "At iter 75/1000, the losses are 1.59639 (train). The time used is 1.806s. \n",
      "At iter 76/1000, the losses are 1.59475 (train). The time used is 1.869s. \n",
      "At iter 77/1000, the losses are 1.59394 (train). The time used is 1.786s. \n",
      "At iter 78/1000, the losses are 1.59286 (train). The time used is 1.787s. \n",
      "At iter 79/1000, the losses are 1.59126 (train). The time used is 1.812s. \n",
      "At iter 80/1000, the losses are 1.58982 (train). The time used is 1.781s. \n",
      "====================================================================================================\n",
      "At iter 80/1000, the losses on all data are 0.83679. The time used is 0.615s. \n",
      "====================================================================================================\n",
      "At iter 81/1000, the losses are 1.58909 (train). The time used is 1.856s. \n",
      "At iter 82/1000, the losses are 1.58805 (train). The time used is 1.826s. \n",
      "At iter 83/1000, the losses are 1.58666 (train). The time used is 1.840s. \n",
      "At iter 84/1000, the losses are 1.58575 (train). The time used is 1.865s. \n",
      "At iter 85/1000, the losses are 1.58497 (train). The time used is 1.847s. \n",
      "At iter 86/1000, the losses are 1.58384 (train). The time used is 1.832s. \n",
      "At iter 87/1000, the losses are 1.58279 (train). The time used is 1.838s. \n",
      "At iter 88/1000, the losses are 1.58210 (train). The time used is 1.842s. \n",
      "At iter 89/1000, the losses are 1.58116 (train). The time used is 1.877s. \n",
      "At iter 90/1000, the losses are 1.58016 (train). The time used is 1.838s. \n",
      "At iter 91/1000, the losses are 1.57940 (train). The time used is 1.798s. \n",
      "At iter 92/1000, the losses are 1.57861 (train). The time used is 1.831s. \n",
      "At iter 93/1000, the losses are 1.57771 (train). The time used is 1.783s. \n",
      "At iter 94/1000, the losses are 1.57685 (train). The time used is 1.817s. \n",
      "At iter 95/1000, the losses are 1.57615 (train). The time used is 1.795s. \n",
      "At iter 96/1000, the losses are 1.57539 (train). The time used is 1.778s. \n",
      "At iter 97/1000, the losses are 1.57457 (train). The time used is 1.687s. \n",
      "At iter 98/1000, the losses are 1.57379 (train). The time used is 1.471s. \n",
      "At iter 99/1000, the losses are 1.57313 (train). The time used is 1.774s. \n",
      "At iter 100/1000, the losses are 1.57246 (train). The time used is 1.837s. \n",
      "====================================================================================================\n",
      "At iter 100/1000, the losses on all data are 0.83764. The time used is 0.655s. \n",
      "====================================================================================================\n",
      "At iter 101/1000, the losses are 1.57175 (train). The time used is 1.850s. \n",
      "At iter 102/1000, the losses are 1.57100 (train). The time used is 1.477s. \n",
      "At iter 103/1000, the losses are 1.57030 (train). The time used is 1.527s. \n",
      "At iter 104/1000, the losses are 1.56968 (train). The time used is 1.500s. \n",
      "At iter 105/1000, the losses are 1.56906 (train). The time used is 1.476s. \n",
      "At iter 106/1000, the losses are 1.56841 (train). The time used is 1.531s. \n",
      "At iter 107/1000, the losses are 1.56775 (train). The time used is 1.497s. \n",
      "At iter 108/1000, the losses are 1.56707 (train). The time used is 1.472s. \n",
      "At iter 109/1000, the losses are 1.56641 (train). The time used is 1.525s. \n",
      "At iter 110/1000, the losses are 1.56577 (train). The time used is 1.747s. \n",
      "At iter 111/1000, the losses are 1.56515 (train). The time used is 1.748s. \n",
      "At iter 112/1000, the losses are 1.56456 (train). The time used is 1.549s. \n",
      "At iter 113/1000, the losses are 1.56397 (train). The time used is 1.500s. \n",
      "At iter 114/1000, the losses are 1.56338 (train). The time used is 1.578s. \n",
      "At iter 115/1000, the losses are 1.56282 (train). The time used is 1.569s. \n",
      "At iter 116/1000, the losses are 1.56226 (train). The time used is 1.557s. \n",
      "At iter 117/1000, the losses are 1.56171 (train). The time used is 1.544s. \n",
      "At iter 118/1000, the losses are 1.56105 (train). The time used is 1.542s. \n",
      "At iter 119/1000, the losses are 1.56033 (train). The time used is 1.507s. \n",
      "At iter 120/1000, the losses are 1.55953 (train). The time used is 1.483s. \n",
      "====================================================================================================\n",
      "At iter 120/1000, the losses on all data are 0.83836. The time used is 0.491s. \n",
      "====================================================================================================\n",
      "At iter 121/1000, the losses are 1.55877 (train). The time used is 1.473s. \n",
      "At iter 122/1000, the losses are 1.55811 (train). The time used is 1.537s. \n",
      "At iter 123/1000, the losses are 1.55755 (train). The time used is 1.572s. \n",
      "At iter 124/1000, the losses are 1.55705 (train). The time used is 1.545s. \n",
      "At iter 125/1000, the losses are 1.55654 (train). The time used is 1.552s. \n",
      "At iter 126/1000, the losses are 1.55602 (train). The time used is 1.482s. \n",
      "At iter 127/1000, the losses are 1.55539 (train). The time used is 1.471s. \n",
      "At iter 128/1000, the losses are 1.55472 (train). The time used is 1.542s. \n",
      "At iter 129/1000, the losses are 1.55401 (train). The time used is 1.497s. \n",
      "At iter 130/1000, the losses are 1.55336 (train). The time used is 1.484s. \n",
      "At iter 131/1000, the losses are 1.55279 (train). The time used is 1.516s. \n",
      "At iter 132/1000, the losses are 1.55229 (train). The time used is 1.488s. \n",
      "At iter 133/1000, the losses are 1.55183 (train). The time used is 1.496s. \n",
      "At iter 134/1000, the losses are 1.55140 (train). The time used is 1.557s. \n",
      "At iter 135/1000, the losses are 1.55102 (train). The time used is 1.572s. \n",
      "At iter 136/1000, the losses are 1.55064 (train). The time used is 1.569s. \n",
      "At iter 137/1000, the losses are 1.55027 (train). The time used is 1.557s. \n",
      "At iter 138/1000, the losses are 1.54980 (train). The time used is 1.542s. \n",
      "At iter 139/1000, the losses are 1.54922 (train). The time used is 1.564s. \n",
      "At iter 140/1000, the losses are 1.54854 (train). The time used is 1.567s. \n",
      "====================================================================================================\n",
      "At iter 140/1000, the losses on all data are 0.83895. The time used is 0.493s. \n",
      "====================================================================================================\n",
      "At iter 141/1000, the losses are 1.54791 (train). The time used is 1.488s. \n",
      "At iter 142/1000, the losses are 1.54741 (train). The time used is 1.569s. \n",
      "At iter 143/1000, the losses are 1.54706 (train). The time used is 1.570s. \n",
      "At iter 144/1000, the losses are 1.54682 (train). The time used is 1.530s. \n",
      "At iter 145/1000, the losses are 1.54652 (train). The time used is 1.507s. \n",
      "At iter 146/1000, the losses are 1.54617 (train). The time used is 1.518s. \n",
      "At iter 147/1000, the losses are 1.54565 (train). The time used is 1.522s. \n",
      "At iter 148/1000, the losses are 1.54506 (train). The time used is 1.514s. \n",
      "At iter 149/1000, the losses are 1.54449 (train). The time used is 1.569s. \n",
      "At iter 150/1000, the losses are 1.54406 (train). The time used is 1.575s. \n",
      "At iter 151/1000, the losses are 1.54371 (train). The time used is 1.554s. \n",
      "At iter 152/1000, the losses are 1.54341 (train). The time used is 1.532s. \n",
      "At iter 153/1000, the losses are 1.54310 (train). The time used is 1.493s. \n",
      "At iter 154/1000, the losses are 1.54276 (train). The time used is 1.723s. \n",
      "At iter 155/1000, the losses are 1.54245 (train). The time used is 1.617s. \n",
      "At iter 156/1000, the losses are 1.54215 (train). The time used is 1.503s. \n",
      "At iter 157/1000, the losses are 1.54190 (train). The time used is 1.486s. \n",
      "At iter 158/1000, the losses are 1.54149 (train). The time used is 1.511s. \n",
      "At iter 159/1000, the losses are 1.54095 (train). The time used is 1.571s. \n",
      "At iter 160/1000, the losses are 1.54047 (train). The time used is 1.569s. \n",
      "====================================================================================================\n",
      "At iter 160/1000, the losses on all data are 0.83930. The time used is 0.504s. \n",
      "====================================================================================================\n",
      "At iter 161/1000, the losses are 1.54011 (train). The time used is 1.509s. \n",
      "At iter 162/1000, the losses are 1.53979 (train). The time used is 1.569s. \n",
      "At iter 163/1000, the losses are 1.53948 (train). The time used is 1.584s. \n",
      "At iter 164/1000, the losses are 1.53915 (train). The time used is 1.920s. \n",
      "At iter 165/1000, the losses are 1.53885 (train). The time used is 1.835s. \n",
      "At iter 166/1000, the losses are 1.53859 (train). The time used is 1.849s. \n",
      "At iter 167/1000, the losses are 1.53840 (train). The time used is 1.835s. \n",
      "At iter 168/1000, the losses are 1.53824 (train). The time used is 1.787s. \n",
      "At iter 169/1000, the losses are 1.53800 (train). The time used is 1.858s. \n",
      "At iter 170/1000, the losses are 1.53766 (train). The time used is 1.904s. \n",
      "At iter 171/1000, the losses are 1.53722 (train). The time used is 1.836s. \n",
      "At iter 172/1000, the losses are 1.53688 (train). The time used is 1.766s. \n",
      "At iter 173/1000, the losses are 1.53675 (train). The time used is 1.882s. \n",
      "At iter 174/1000, the losses are 1.53660 (train). The time used is 1.618s. \n",
      "At iter 175/1000, the losses are 1.53639 (train). The time used is 1.564s. \n",
      "At iter 176/1000, the losses are 1.53582 (train). The time used is 1.576s. \n",
      "At iter 177/1000, the losses are 1.53543 (train). The time used is 1.489s. \n",
      "At iter 178/1000, the losses are 1.53539 (train). The time used is 1.509s. \n",
      "At iter 179/1000, the losses are 1.53531 (train). The time used is 1.557s. \n",
      "At iter 180/1000, the losses are 1.53497 (train). The time used is 1.523s. \n",
      "====================================================================================================\n",
      "At iter 180/1000, the losses on all data are 0.83973. The time used is 0.620s. \n",
      "====================================================================================================\n",
      "At iter 181/1000, the losses are 1.53459 (train). The time used is 1.809s. \n",
      "At iter 182/1000, the losses are 1.53452 (train). The time used is 1.800s. \n",
      "At iter 183/1000, the losses are 1.53459 (train). The time used is 1.870s. \n",
      "At iter 184/1000, the losses are 1.53435 (train). The time used is 1.810s. \n",
      "At iter 185/1000, the losses are 1.53402 (train). The time used is 1.850s. \n",
      "At iter 186/1000, the losses are 1.53385 (train). The time used is 1.824s. \n",
      "At iter 187/1000, the losses are 1.53374 (train). The time used is 1.596s. \n",
      "At iter 188/1000, the losses are 1.53360 (train). The time used is 1.618s. \n",
      "At iter 189/1000, the losses are 1.53308 (train). The time used is 1.802s. \n",
      "At iter 190/1000, the losses are 1.53260 (train). The time used is 1.824s. \n",
      "At iter 191/1000, the losses are 1.53234 (train). The time used is 1.862s. \n",
      "At iter 192/1000, the losses are 1.53225 (train). The time used is 1.808s. \n",
      "At iter 193/1000, the losses are 1.53226 (train). The time used is 1.884s. \n",
      "At iter 194/1000, the losses are 1.53203 (train). The time used is 1.738s. \n",
      "At iter 195/1000, the losses are 1.53187 (train). The time used is 1.523s. \n",
      "At iter 196/1000, the losses are 1.53177 (train). The time used is 1.669s. \n",
      "At iter 197/1000, the losses are 1.53162 (train). The time used is 1.836s. \n",
      "At iter 198/1000, the losses are 1.53137 (train). The time used is 1.789s. \n",
      "At iter 199/1000, the losses are 1.53101 (train). The time used is 1.807s. \n",
      "At iter 200/1000, the losses are 1.53071 (train). The time used is 1.854s. \n",
      "====================================================================================================\n",
      "At iter 200/1000, the losses on all data are 0.83975. The time used is 0.648s. \n",
      "====================================================================================================\n",
      "At iter 201/1000, the losses are 1.53052 (train). The time used is 1.874s. \n",
      "At iter 202/1000, the losses are 1.53042 (train). The time used is 1.828s. \n",
      "At iter 203/1000, the losses are 1.53029 (train). The time used is 1.863s. \n",
      "At iter 204/1000, the losses are 1.53018 (train). The time used is 1.801s. \n",
      "At iter 205/1000, the losses are 1.53015 (train). The time used is 1.801s. \n",
      "At iter 206/1000, the losses are 1.53025 (train). The time used is 1.797s. \n",
      "At iter 207/1000, the losses are 1.53038 (train). The time used is 1.779s. \n",
      "At iter 208/1000, the losses are 1.53036 (train). The time used is 1.496s. \n",
      "At iter 209/1000, the losses are 1.52964 (train). The time used is 1.602s. \n",
      "At iter 210/1000, the losses are 1.52911 (train). The time used is 1.583s. \n",
      "At iter 211/1000, the losses are 1.52913 (train). The time used is 1.557s. \n",
      "At iter 212/1000, the losses are 1.52920 (train). The time used is 1.512s. \n",
      "At iter 213/1000, the losses are 1.52895 (train). The time used is 1.491s. \n",
      "At iter 214/1000, the losses are 1.52877 (train). The time used is 1.567s. \n",
      "At iter 215/1000, the losses are 1.52875 (train). The time used is 1.859s. \n",
      "At iter 216/1000, the losses are 1.52845 (train). The time used is 1.838s. \n",
      "At iter 217/1000, the losses are 1.52805 (train). The time used is 1.719s. \n",
      "At iter 218/1000, the losses are 1.52813 (train). The time used is 1.729s. \n",
      "At iter 219/1000, the losses are 1.52825 (train). The time used is 1.789s. \n",
      "At iter 220/1000, the losses are 1.52771 (train). The time used is 1.858s. \n",
      "====================================================================================================\n",
      "At iter 220/1000, the losses on all data are 0.83997. The time used is 0.625s. \n",
      "====================================================================================================\n",
      "At iter 221/1000, the losses are 1.52746 (train). The time used is 1.759s. \n",
      "At iter 222/1000, the losses are 1.52756 (train). The time used is 1.751s. \n",
      "At iter 223/1000, the losses are 1.52723 (train). The time used is 1.823s. \n",
      "At iter 224/1000, the losses are 1.52700 (train). The time used is 1.545s. \n",
      "At iter 225/1000, the losses are 1.52707 (train). The time used is 1.541s. \n",
      "At iter 226/1000, the losses are 1.52700 (train). The time used is 1.555s. \n",
      "At iter 227/1000, the losses are 1.52680 (train). The time used is 1.506s. \n",
      "At iter 228/1000, the losses are 1.52685 (train). The time used is 1.499s. \n",
      "At iter 229/1000, the losses are 1.52694 (train). The time used is 1.565s. \n",
      "At iter 230/1000, the losses are 1.52664 (train). The time used is 1.580s. \n",
      "At iter 231/1000, the losses are 1.52631 (train). The time used is 1.579s. \n",
      "At iter 232/1000, the losses are 1.52633 (train). The time used is 1.611s. \n",
      "At iter 233/1000, the losses are 1.52654 (train). The time used is 1.746s. \n",
      "At iter 234/1000, the losses are 1.52678 (train). The time used is 1.870s. \n",
      "At iter 235/1000, the losses are 1.52611 (train). The time used is 1.803s. \n",
      "At iter 236/1000, the losses are 1.52570 (train). The time used is 1.806s. \n",
      "At iter 237/1000, the losses are 1.52537 (train). The time used is 1.863s. \n",
      "At iter 238/1000, the losses are 1.52540 (train). The time used is 1.821s. \n",
      "At iter 239/1000, the losses are 1.52567 (train). The time used is 1.794s. \n",
      "At iter 240/1000, the losses are 1.52559 (train). The time used is 1.845s. \n",
      "====================================================================================================\n",
      "At iter 240/1000, the losses on all data are 0.83988. The time used is 0.516s. \n",
      "====================================================================================================\n",
      "At iter 241/1000, the losses are 1.52511 (train). The time used is 1.526s. \n",
      "At iter 242/1000, the losses are 1.52479 (train). The time used is 1.565s. \n",
      "At iter 243/1000, the losses are 1.52470 (train). The time used is 1.495s. \n",
      "At iter 244/1000, the losses are 1.52463 (train). The time used is 1.501s. \n",
      "At iter 245/1000, the losses are 1.52468 (train). The time used is 1.547s. \n",
      "At iter 246/1000, the losses are 1.52495 (train). The time used is 1.561s. \n",
      "At iter 247/1000, the losses are 1.52493 (train). The time used is 1.572s. \n",
      "At iter 248/1000, the losses are 1.52449 (train). The time used is 1.531s. \n",
      "At iter 249/1000, the losses are 1.52418 (train). The time used is 1.494s. \n",
      "At iter 250/1000, the losses are 1.52447 (train). The time used is 1.497s. \n",
      "At iter 251/1000, the losses are 1.52481 (train). The time used is 1.541s. \n",
      "At iter 252/1000, the losses are 1.52456 (train). The time used is 1.585s. \n",
      "At iter 253/1000, the losses are 1.52404 (train). The time used is 1.483s. \n",
      "At iter 254/1000, the losses are 1.52395 (train). The time used is 1.504s. \n",
      "At iter 255/1000, the losses are 1.52406 (train). The time used is 1.511s. \n",
      "At iter 256/1000, the losses are 1.52388 (train). The time used is 1.494s. \n",
      "At iter 257/1000, the losses are 1.52340 (train). The time used is 1.499s. \n",
      "At iter 258/1000, the losses are 1.52327 (train). The time used is 1.485s. \n",
      "At iter 259/1000, the losses are 1.52318 (train). The time used is 1.502s. \n",
      "At iter 260/1000, the losses are 1.52309 (train). The time used is 1.497s. \n",
      "====================================================================================================\n",
      "At iter 260/1000, the losses on all data are 0.83992. The time used is 0.500s. \n",
      "====================================================================================================\n",
      "At iter 261/1000, the losses are 1.52303 (train). The time used is 1.493s. \n",
      "At iter 262/1000, the losses are 1.52298 (train). The time used is 1.495s. \n",
      "At iter 263/1000, the losses are 1.52301 (train). The time used is 1.543s. \n",
      "At iter 264/1000, the losses are 1.52300 (train). The time used is 1.487s. \n",
      "At iter 265/1000, the losses are 1.52313 (train). The time used is 1.510s. \n",
      "At iter 266/1000, the losses are 1.52322 (train). The time used is 1.760s. \n",
      "At iter 267/1000, the losses are 1.52312 (train). The time used is 1.767s. \n",
      "At iter 268/1000, the losses are 1.52284 (train). The time used is 1.808s. \n",
      "At iter 269/1000, the losses are 1.52265 (train). The time used is 1.749s. \n",
      "At iter 270/1000, the losses are 1.52234 (train). The time used is 1.779s. \n",
      "At iter 271/1000, the losses are 1.52216 (train). The time used is 1.756s. \n",
      "At iter 272/1000, the losses are 1.52195 (train). The time used is 1.749s. \n",
      "At iter 273/1000, the losses are 1.52183 (train). The time used is 1.898s. \n",
      "At iter 274/1000, the losses are 1.52193 (train). The time used is 1.798s. \n",
      "At iter 275/1000, the losses are 1.52206 (train). The time used is 1.890s. \n",
      "At iter 276/1000, the losses are 1.52218 (train). The time used is 1.813s. \n",
      "At iter 277/1000, the losses are 1.52193 (train). The time used is 1.817s. \n",
      "At iter 278/1000, the losses are 1.52170 (train). The time used is 1.855s. \n",
      "At iter 279/1000, the losses are 1.52156 (train). The time used is 1.797s. \n",
      "At iter 280/1000, the losses are 1.52154 (train). The time used is 1.869s. \n",
      "====================================================================================================\n",
      "At iter 280/1000, the losses on all data are 0.84008. The time used is 0.612s. \n",
      "====================================================================================================\n",
      "At iter 281/1000, the losses are 1.52151 (train). The time used is 1.815s. \n",
      "At iter 282/1000, the losses are 1.52135 (train). The time used is 1.789s. \n",
      "At iter 283/1000, the losses are 1.52124 (train). The time used is 1.786s. \n",
      "At iter 284/1000, the losses are 1.52115 (train). The time used is 1.797s. \n",
      "At iter 285/1000, the losses are 1.52127 (train). The time used is 1.816s. \n",
      "At iter 286/1000, the losses are 1.52139 (train). The time used is 1.598s. \n",
      "At iter 287/1000, the losses are 1.52139 (train). The time used is 1.588s. \n",
      "At iter 288/1000, the losses are 1.52121 (train). The time used is 1.559s. \n",
      "At iter 289/1000, the losses are 1.52101 (train). The time used is 1.591s. \n",
      "At iter 290/1000, the losses are 1.52088 (train). The time used is 1.565s. \n",
      "At iter 291/1000, the losses are 1.52097 (train). The time used is 1.560s. \n",
      "At iter 292/1000, the losses are 1.52089 (train). The time used is 1.805s. \n",
      "At iter 293/1000, the losses are 1.52078 (train). The time used is 1.853s. \n",
      "At iter 294/1000, the losses are 1.52049 (train). The time used is 1.867s. \n",
      "At iter 295/1000, the losses are 1.52043 (train). The time used is 1.851s. \n",
      "At iter 296/1000, the losses are 1.52067 (train). The time used is 1.916s. \n",
      "At iter 297/1000, the losses are 1.52082 (train). The time used is 1.737s. \n",
      "At iter 298/1000, the losses are 1.52085 (train). The time used is 1.716s. \n",
      "At iter 299/1000, the losses are 1.52018 (train). The time used is 1.851s. \n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "At iter 300/1000, the losses are 1.51989 (train). The time used is 1.633s. \n",
      "====================================================================================================\n",
      "At iter 300/1000, the losses on all data are 0.84018. The time used is 0.492s. \n",
      "====================================================================================================\n",
      "At iter 301/1000, the losses are 1.52000 (train). The time used is 1.524s. \n",
      "At iter 302/1000, the losses are 1.51971 (train). The time used is 1.572s. \n",
      "At iter 303/1000, the losses are 1.51988 (train). The time used is 1.739s. \n",
      "At iter 304/1000, the losses are 1.51963 (train). The time used is 1.818s. \n",
      "At iter 305/1000, the losses are 1.51977 (train). The time used is 1.799s. \n",
      "At iter 306/1000, the losses are 1.51957 (train). The time used is 1.874s. \n",
      "At iter 307/1000, the losses are 1.51966 (train). The time used is 1.786s. \n",
      "At iter 308/1000, the losses are 1.51950 (train). The time used is 1.808s. \n",
      "At iter 309/1000, the losses are 1.51956 (train). The time used is 1.578s. \n",
      "At iter 310/1000, the losses are 1.51944 (train). The time used is 1.488s. \n",
      "At iter 311/1000, the losses are 1.51947 (train). The time used is 1.603s. \n",
      "At iter 312/1000, the losses are 1.51937 (train). The time used is 1.543s. \n",
      "At iter 313/1000, the losses are 1.51938 (train). The time used is 1.492s. \n",
      "At iter 314/1000, the losses are 1.51929 (train). The time used is 1.506s. \n",
      "At iter 315/1000, the losses are 1.51930 (train). The time used is 1.550s. \n",
      "At iter 316/1000, the losses are 1.51923 (train). The time used is 1.640s. \n",
      "At iter 317/1000, the losses are 1.51922 (train). The time used is 1.488s. \n",
      "At iter 318/1000, the losses are 1.51915 (train). The time used is 1.509s. \n",
      "At iter 319/1000, the losses are 1.51914 (train). The time used is 1.509s. \n",
      "At iter 320/1000, the losses are 1.51909 (train). The time used is 1.696s. \n",
      "====================================================================================================\n",
      "At iter 320/1000, the losses on all data are 0.84023. The time used is 0.646s. \n",
      "====================================================================================================\n",
      "At iter 321/1000, the losses are 1.51907 (train). The time used is 1.836s. \n",
      "At iter 322/1000, the losses are 1.51901 (train). The time used is 1.829s. \n",
      "At iter 323/1000, the losses are 1.51900 (train). The time used is 1.812s. \n",
      "At iter 324/1000, the losses are 1.51895 (train). The time used is 1.817s. \n",
      "At iter 325/1000, the losses are 1.51893 (train). The time used is 1.821s. \n",
      "At iter 326/1000, the losses are 1.51887 (train). The time used is 1.813s. \n",
      "At iter 327/1000, the losses are 1.51886 (train). The time used is 1.837s. \n",
      "At iter 328/1000, the losses are 1.51881 (train). The time used is 1.839s. \n",
      "At iter 329/1000, the losses are 1.51879 (train). The time used is 1.706s. \n",
      "At iter 330/1000, the losses are 1.51874 (train). The time used is 1.482s. \n",
      "At iter 331/1000, the losses are 1.51872 (train). The time used is 1.559s. \n",
      "At iter 332/1000, the losses are 1.51868 (train). The time used is 1.478s. \n",
      "At iter 333/1000, the losses are 1.51865 (train). The time used is 1.508s. \n",
      "At iter 334/1000, the losses are 1.51861 (train). The time used is 1.739s. \n",
      "At iter 335/1000, the losses are 1.51859 (train). The time used is 1.800s. \n",
      "At iter 336/1000, the losses are 1.51856 (train). The time used is 1.804s. \n",
      "At iter 337/1000, the losses are 1.51854 (train). The time used is 1.826s. \n",
      "At iter 338/1000, the losses are 1.51850 (train). The time used is 1.875s. \n",
      "At iter 339/1000, the losses are 1.51846 (train). The time used is 1.794s. \n",
      "At iter 340/1000, the losses are 1.51843 (train). The time used is 1.799s. \n",
      "====================================================================================================\n",
      "At iter 340/1000, the losses on all data are 0.84023. The time used is 0.630s. \n",
      "====================================================================================================\n",
      "At iter 341/1000, the losses are 1.51839 (train). The time used is 1.803s. \n",
      "At iter 342/1000, the losses are 1.51837 (train). The time used is 1.792s. \n",
      "At iter 343/1000, the losses are 1.51833 (train). The time used is 1.809s. \n",
      "At iter 344/1000, the losses are 1.51832 (train). The time used is 1.832s. \n",
      "At iter 345/1000, the losses are 1.51830 (train). The time used is 1.754s. \n",
      "At iter 346/1000, the losses are 1.51827 (train). The time used is 1.864s. \n",
      "At iter 347/1000, the losses are 1.51823 (train). The time used is 1.815s. \n",
      "At iter 348/1000, the losses are 1.51819 (train). The time used is 1.802s. \n",
      "At iter 349/1000, the losses are 1.51815 (train). The time used is 1.822s. \n",
      "At iter 350/1000, the losses are 1.51812 (train). The time used is 1.820s. \n",
      "At iter 351/1000, the losses are 1.51808 (train). The time used is 1.789s. \n",
      "At iter 352/1000, the losses are 1.51805 (train). The time used is 1.826s. \n",
      "At iter 353/1000, the losses are 1.51802 (train). The time used is 1.796s. \n",
      "At iter 354/1000, the losses are 1.51799 (train). The time used is 1.777s. \n",
      "At iter 355/1000, the losses are 1.51796 (train). The time used is 1.848s. \n",
      "At iter 356/1000, the losses are 1.51794 (train). The time used is 1.821s. \n",
      "At iter 357/1000, the losses are 1.51792 (train). The time used is 1.675s. \n",
      "At iter 358/1000, the losses are 1.51793 (train). The time used is 1.573s. \n",
      "At iter 359/1000, the losses are 1.51792 (train). The time used is 1.542s. \n",
      "At iter 360/1000, the losses are 1.51788 (train). The time used is 1.587s. \n",
      "====================================================================================================\n",
      "At iter 360/1000, the losses on all data are 0.84029. The time used is 0.627s. \n",
      "====================================================================================================\n",
      "At iter 361/1000, the losses are 1.51781 (train). The time used is 1.923s. \n",
      "At iter 362/1000, the losses are 1.51777 (train). The time used is 1.808s. \n",
      "At iter 363/1000, the losses are 1.51773 (train). The time used is 1.787s. \n",
      "At iter 364/1000, the losses are 1.51771 (train). The time used is 1.845s. \n",
      "At iter 365/1000, the losses are 1.51770 (train). The time used is 1.795s. \n",
      "At iter 366/1000, the losses are 1.51770 (train). The time used is 1.788s. \n",
      "At iter 367/1000, the losses are 1.51767 (train). The time used is 1.836s. \n",
      "At iter 368/1000, the losses are 1.51763 (train). The time used is 1.787s. \n",
      "At iter 369/1000, the losses are 1.51758 (train). The time used is 1.859s. \n",
      "At iter 370/1000, the losses are 1.51755 (train). The time used is 1.591s. \n",
      "At iter 371/1000, the losses are 1.51751 (train). The time used is 1.573s. \n",
      "At iter 372/1000, the losses are 1.51748 (train). The time used is 1.530s. \n",
      "At iter 373/1000, the losses are 1.51746 (train). The time used is 1.490s. \n",
      "At iter 374/1000, the losses are 1.51746 (train). The time used is 1.525s. \n",
      "At iter 375/1000, the losses are 1.51744 (train). The time used is 1.503s. \n",
      "At iter 376/1000, the losses are 1.51743 (train). The time used is 1.485s. \n",
      "At iter 377/1000, the losses are 1.51739 (train). The time used is 1.714s. \n",
      "At iter 378/1000, the losses are 1.51737 (train). The time used is 1.793s. \n",
      "At iter 379/1000, the losses are 1.51732 (train). The time used is 1.796s. \n",
      "At iter 380/1000, the losses are 1.51727 (train). The time used is 1.804s. \n",
      "====================================================================================================\n",
      "At iter 380/1000, the losses on all data are 0.84031. The time used is 0.629s. \n",
      "====================================================================================================\n",
      "At iter 381/1000, the losses are 1.51722 (train). The time used is 1.822s. \n",
      "At iter 382/1000, the losses are 1.51719 (train). The time used is 1.807s. \n",
      "At iter 383/1000, the losses are 1.51716 (train). The time used is 1.844s. \n",
      "At iter 384/1000, the losses are 1.51713 (train). The time used is 1.799s. \n",
      "At iter 385/1000, the losses are 1.51710 (train). The time used is 1.807s. \n",
      "At iter 386/1000, the losses are 1.51709 (train). The time used is 1.793s. \n",
      "At iter 387/1000, the losses are 1.51709 (train). The time used is 1.803s. \n",
      "At iter 388/1000, the losses are 1.51712 (train). The time used is 1.826s. \n",
      "At iter 389/1000, the losses are 1.51714 (train). The time used is 1.511s. \n",
      "At iter 390/1000, the losses are 1.51707 (train). The time used is 1.525s. \n",
      "At iter 391/1000, the losses are 1.51700 (train). The time used is 1.500s. \n",
      "At iter 392/1000, the losses are 1.51694 (train). The time used is 1.498s. \n",
      "At iter 393/1000, the losses are 1.51690 (train). The time used is 1.501s. \n",
      "At iter 394/1000, the losses are 1.51687 (train). The time used is 1.529s. \n",
      "At iter 395/1000, the losses are 1.51684 (train). The time used is 1.552s. \n",
      "At iter 396/1000, the losses are 1.51683 (train). The time used is 1.493s. \n",
      "At iter 397/1000, the losses are 1.51684 (train). The time used is 1.532s. \n",
      "At iter 398/1000, the losses are 1.51687 (train). The time used is 1.568s. \n",
      "At iter 399/1000, the losses are 1.51689 (train). The time used is 1.565s. \n",
      "At iter 400/1000, the losses are 1.51686 (train). The time used is 1.533s. \n",
      "====================================================================================================\n",
      "At iter 400/1000, the losses on all data are 0.84035. The time used is 0.502s. \n",
      "====================================================================================================\n",
      "At iter 401/1000, the losses are 1.51676 (train). The time used is 1.511s. \n",
      "At iter 402/1000, the losses are 1.51668 (train). The time used is 1.502s. \n",
      "At iter 403/1000, the losses are 1.51662 (train). The time used is 1.488s. \n",
      "At iter 404/1000, the losses are 1.51659 (train). The time used is 1.589s. \n",
      "At iter 405/1000, the losses are 1.51658 (train). The time used is 1.571s. \n",
      "At iter 406/1000, the losses are 1.51657 (train). The time used is 1.564s. \n",
      "At iter 407/1000, the losses are 1.51656 (train). The time used is 1.583s. \n",
      "At iter 408/1000, the losses are 1.51657 (train). The time used is 1.521s. \n",
      "At iter 409/1000, the losses are 1.51661 (train). The time used is 1.507s. \n",
      "At iter 410/1000, the losses are 1.51662 (train). The time used is 1.507s. \n",
      "At iter 411/1000, the losses are 1.51654 (train). The time used is 1.485s. \n",
      "At iter 412/1000, the losses are 1.51643 (train). The time used is 1.556s. \n",
      "At iter 413/1000, the losses are 1.51637 (train). The time used is 1.575s. \n",
      "At iter 414/1000, the losses are 1.51636 (train). The time used is 1.513s. \n",
      "At iter 415/1000, the losses are 1.51639 (train). The time used is 1.484s. \n",
      "At iter 416/1000, the losses are 1.51646 (train). The time used is 1.573s. \n",
      "At iter 417/1000, the losses are 1.51643 (train). The time used is 1.521s. \n",
      "At iter 418/1000, the losses are 1.51635 (train). The time used is 1.514s. \n",
      "At iter 419/1000, the losses are 1.51626 (train). The time used is 1.560s. \n",
      "At iter 420/1000, the losses are 1.51621 (train). The time used is 1.569s. \n",
      "====================================================================================================\n",
      "At iter 420/1000, the losses on all data are 0.84029. The time used is 0.504s. \n",
      "====================================================================================================\n",
      "At iter 421/1000, the losses are 1.51619 (train). The time used is 1.509s. \n",
      "At iter 422/1000, the losses are 1.51618 (train). The time used is 1.528s. \n",
      "At iter 423/1000, the losses are 1.51619 (train). The time used is 1.497s. \n",
      "At iter 424/1000, the losses are 1.51621 (train). The time used is 1.544s. \n",
      "At iter 425/1000, the losses are 1.51623 (train). The time used is 1.580s. \n",
      "At iter 426/1000, the losses are 1.51618 (train). The time used is 1.568s. \n",
      "At iter 427/1000, the losses are 1.51612 (train). The time used is 1.510s. \n",
      "At iter 428/1000, the losses are 1.51605 (train). The time used is 1.492s. \n",
      "At iter 429/1000, the losses are 1.51599 (train). The time used is 1.517s. \n",
      "At iter 430/1000, the losses are 1.51597 (train). The time used is 1.667s. \n",
      "At iter 431/1000, the losses are 1.51597 (train). The time used is 1.877s. \n",
      "At iter 432/1000, the losses are 1.51600 (train). The time used is 1.792s. \n",
      "At iter 433/1000, the losses are 1.51601 (train). The time used is 1.873s. \n",
      "At iter 434/1000, the losses are 1.51601 (train). The time used is 1.798s. \n",
      "At iter 435/1000, the losses are 1.51595 (train). The time used is 1.793s. \n",
      "At iter 436/1000, the losses are 1.51589 (train). The time used is 1.481s. \n",
      "At iter 437/1000, the losses are 1.51582 (train). The time used is 1.545s. \n",
      "At iter 438/1000, the losses are 1.51577 (train). The time used is 1.536s. \n",
      "At iter 439/1000, the losses are 1.51574 (train). The time used is 1.486s. \n",
      "At iter 440/1000, the losses are 1.51574 (train). The time used is 1.509s. \n",
      "====================================================================================================\n",
      "At iter 440/1000, the losses on all data are 0.84028. The time used is 0.500s. \n",
      "====================================================================================================\n",
      "At iter 441/1000, the losses are 1.51576 (train). The time used is 1.508s. \n",
      "At iter 442/1000, the losses are 1.51579 (train). The time used is 1.554s. \n",
      "At iter 443/1000, the losses are 1.51583 (train). The time used is 1.574s. \n",
      "At iter 444/1000, the losses are 1.51581 (train). The time used is 1.574s. \n",
      "At iter 445/1000, the losses are 1.51575 (train). The time used is 1.708s. \n",
      "At iter 446/1000, the losses are 1.51565 (train). The time used is 1.825s. \n",
      "At iter 447/1000, the losses are 1.51558 (train). The time used is 1.826s. \n",
      "At iter 448/1000, the losses are 1.51553 (train). The time used is 1.915s. \n",
      "At iter 449/1000, the losses are 1.51551 (train). The time used is 1.817s. \n",
      "At iter 450/1000, the losses are 1.51550 (train). The time used is 1.843s. \n",
      "At iter 451/1000, the losses are 1.51550 (train). The time used is 1.917s. \n",
      "At iter 452/1000, the losses are 1.51551 (train). The time used is 1.813s. \n",
      "At iter 453/1000, the losses are 1.51552 (train). The time used is 1.863s. \n",
      "At iter 454/1000, the losses are 1.51556 (train). The time used is 1.807s. \n",
      "At iter 455/1000, the losses are 1.51556 (train). The time used is 1.808s. \n",
      "At iter 456/1000, the losses are 1.51555 (train). The time used is 1.809s. \n",
      "At iter 457/1000, the losses are 1.51544 (train). The time used is 1.807s. \n",
      "At iter 458/1000, the losses are 1.51537 (train). The time used is 1.808s. \n",
      "At iter 459/1000, the losses are 1.51532 (train). The time used is 1.788s. \n",
      "At iter 460/1000, the losses are 1.51531 (train). The time used is 1.891s. \n",
      "====================================================================================================\n",
      "At iter 460/1000, the losses on all data are 0.84036. The time used is 0.657s. \n",
      "====================================================================================================\n",
      "At iter 461/1000, the losses are 1.51532 (train). The time used is 1.883s. \n",
      "At iter 462/1000, the losses are 1.51530 (train). The time used is 1.798s. \n",
      "At iter 463/1000, the losses are 1.51525 (train). The time used is 1.917s. \n",
      "At iter 464/1000, the losses are 1.51522 (train). The time used is 1.770s. \n",
      "At iter 465/1000, the losses are 1.51523 (train). The time used is 1.842s. \n",
      "At iter 466/1000, the losses are 1.51530 (train). The time used is 1.801s. \n",
      "At iter 467/1000, the losses are 1.51540 (train). The time used is 1.818s. \n",
      "At iter 468/1000, the losses are 1.51532 (train). The time used is 1.659s. \n",
      "At iter 469/1000, the losses are 1.51523 (train). The time used is 1.586s. \n",
      "At iter 470/1000, the losses are 1.51513 (train). The time used is 1.575s. \n",
      "At iter 471/1000, the losses are 1.51506 (train). The time used is 1.572s. \n",
      "At iter 472/1000, the losses are 1.51503 (train). The time used is 1.554s. \n",
      "At iter 473/1000, the losses are 1.51505 (train). The time used is 1.542s. \n",
      "At iter 474/1000, the losses are 1.51514 (train). The time used is 1.489s. \n",
      "At iter 475/1000, the losses are 1.51518 (train). The time used is 1.533s. \n",
      "At iter 476/1000, the losses are 1.51513 (train). The time used is 1.548s. \n",
      "At iter 477/1000, the losses are 1.51499 (train). The time used is 1.612s. \n",
      "At iter 478/1000, the losses are 1.51491 (train). The time used is 1.837s. \n",
      "At iter 479/1000, the losses are 1.51487 (train). The time used is 1.879s. \n",
      "At iter 480/1000, the losses are 1.51486 (train). The time used is 1.888s. \n",
      "====================================================================================================\n",
      "At iter 480/1000, the losses on all data are 0.84031. The time used is 0.632s. \n",
      "====================================================================================================\n",
      "At iter 481/1000, the losses are 1.51487 (train). The time used is 1.915s. \n",
      "At iter 482/1000, the losses are 1.51489 (train). The time used is 1.848s. \n",
      "At iter 483/1000, the losses are 1.51495 (train). The time used is 1.928s. \n",
      "At iter 484/1000, the losses are 1.51495 (train). The time used is 1.839s. \n",
      "At iter 485/1000, the losses are 1.51490 (train). The time used is 1.847s. \n",
      "At iter 486/1000, the losses are 1.51479 (train). The time used is 1.870s. \n",
      "At iter 487/1000, the losses are 1.51471 (train). The time used is 1.853s. \n",
      "At iter 488/1000, the losses are 1.51467 (train). The time used is 1.837s. \n",
      "At iter 489/1000, the losses are 1.51465 (train). The time used is 1.821s. \n",
      "At iter 490/1000, the losses are 1.51467 (train). The time used is 1.893s. \n",
      "At iter 491/1000, the losses are 1.51469 (train). The time used is 1.840s. \n",
      "At iter 492/1000, the losses are 1.51476 (train). The time used is 1.697s. \n",
      "At iter 493/1000, the losses are 1.51475 (train). The time used is 1.501s. \n",
      "At iter 494/1000, the losses are 1.51473 (train). The time used is 1.494s. \n",
      "At iter 495/1000, the losses are 1.51465 (train). The time used is 1.560s. \n",
      "At iter 496/1000, the losses are 1.51461 (train). The time used is 1.757s. \n",
      "At iter 497/1000, the losses are 1.51459 (train). The time used is 1.799s. \n",
      "At iter 498/1000, the losses are 1.51459 (train). The time used is 1.784s. \n",
      "At iter 499/1000, the losses are 1.51457 (train). The time used is 1.857s. \n",
      "At iter 500/1000, the losses are 1.51456 (train). The time used is 1.792s. \n",
      "====================================================================================================\n",
      "At iter 500/1000, the losses on all data are 0.84027. The time used is 0.647s. \n",
      "====================================================================================================\n",
      "At iter 501/1000, the losses are 1.51460 (train). The time used is 1.811s. \n",
      "At iter 502/1000, the losses are 1.51462 (train). The time used is 1.796s. \n",
      "At iter 503/1000, the losses are 1.51459 (train). The time used is 1.805s. \n",
      "At iter 504/1000, the losses are 1.51448 (train). The time used is 1.798s. \n",
      "At iter 505/1000, the losses are 1.51439 (train). The time used is 1.850s. \n",
      "At iter 506/1000, the losses are 1.51434 (train). The time used is 1.800s. \n",
      "At iter 507/1000, the losses are 1.51434 (train). The time used is 1.833s. \n",
      "At iter 508/1000, the losses are 1.51438 (train). The time used is 1.843s. \n",
      "At iter 509/1000, the losses are 1.51444 (train). The time used is 1.795s. \n",
      "At iter 510/1000, the losses are 1.51451 (train). The time used is 1.791s. \n",
      "At iter 511/1000, the losses are 1.51443 (train). The time used is 1.830s. \n",
      "At iter 512/1000, the losses are 1.51432 (train). The time used is 1.820s. \n",
      "At iter 513/1000, the losses are 1.51420 (train). The time used is 1.799s. \n",
      "At iter 514/1000, the losses are 1.51415 (train). The time used is 1.812s. \n",
      "At iter 515/1000, the losses are 1.51417 (train). The time used is 1.853s. \n",
      "At iter 516/1000, the losses are 1.51423 (train). The time used is 1.812s. \n",
      "At iter 517/1000, the losses are 1.51430 (train). The time used is 1.842s. \n",
      "At iter 518/1000, the losses are 1.51425 (train). The time used is 1.815s. \n",
      "At iter 519/1000, the losses are 1.51419 (train). The time used is 1.812s. \n",
      "At iter 520/1000, the losses are 1.51407 (train). The time used is 1.760s. \n",
      "====================================================================================================\n",
      "At iter 520/1000, the losses on all data are 0.84040. The time used is 0.628s. \n",
      "====================================================================================================\n",
      "At iter 521/1000, the losses are 1.51403 (train). The time used is 1.814s. \n",
      "At iter 522/1000, the losses are 1.51406 (train). The time used is 1.590s. \n",
      "At iter 523/1000, the losses are 1.51417 (train). The time used is 1.528s. \n",
      "At iter 524/1000, the losses are 1.51433 (train). The time used is 1.532s. \n",
      "At iter 525/1000, the losses are 1.51432 (train). The time used is 1.503s. \n",
      "At iter 526/1000, the losses are 1.51422 (train). The time used is 1.710s. \n",
      "At iter 527/1000, the losses are 1.51402 (train). The time used is 1.810s. \n",
      "At iter 528/1000, the losses are 1.51391 (train). The time used is 1.808s. \n",
      "At iter 529/1000, the losses are 1.51393 (train). The time used is 1.903s. \n",
      "At iter 530/1000, the losses are 1.51403 (train). The time used is 1.806s. \n",
      "At iter 531/1000, the losses are 1.51412 (train). The time used is 1.601s. \n",
      "At iter 532/1000, the losses are 1.51403 (train). The time used is 1.495s. \n",
      "At iter 533/1000, the losses are 1.51391 (train). The time used is 1.498s. \n",
      "At iter 534/1000, the losses are 1.51380 (train). The time used is 1.486s. \n",
      "At iter 535/1000, the losses are 1.51379 (train). The time used is 1.559s. \n",
      "At iter 536/1000, the losses are 1.51388 (train). The time used is 1.580s. \n",
      "At iter 537/1000, the losses are 1.51395 (train). The time used is 1.561s. \n",
      "At iter 538/1000, the losses are 1.51396 (train). The time used is 1.510s. \n",
      "At iter 539/1000, the losses are 1.51378 (train). The time used is 1.511s. \n",
      "At iter 540/1000, the losses are 1.51367 (train). The time used is 1.492s. \n",
      "====================================================================================================\n",
      "At iter 540/1000, the losses on all data are 0.84038. The time used is 0.490s. \n",
      "====================================================================================================\n",
      "At iter 541/1000, the losses are 1.51364 (train). The time used is 1.483s. \n",
      "At iter 542/1000, the losses are 1.51369 (train). The time used is 1.512s. \n",
      "At iter 543/1000, the losses are 1.51377 (train). The time used is 1.497s. \n",
      "At iter 544/1000, the losses are 1.51375 (train). The time used is 1.486s. \n",
      "At iter 545/1000, the losses are 1.51369 (train). The time used is 1.489s. \n",
      "At iter 546/1000, the losses are 1.51360 (train). The time used is 1.493s. \n",
      "At iter 547/1000, the losses are 1.51356 (train). The time used is 1.563s. \n",
      "At iter 548/1000, the losses are 1.51358 (train). The time used is 1.502s. \n",
      "At iter 549/1000, the losses are 1.51362 (train). The time used is 1.495s. \n",
      "At iter 550/1000, the losses are 1.51364 (train). The time used is 1.540s. \n",
      "At iter 551/1000, the losses are 1.51361 (train). The time used is 1.550s. \n",
      "At iter 552/1000, the losses are 1.51353 (train). The time used is 1.512s. \n",
      "At iter 553/1000, the losses are 1.51345 (train). The time used is 1.495s. \n",
      "At iter 554/1000, the losses are 1.51339 (train). The time used is 1.543s. \n",
      "At iter 555/1000, the losses are 1.51338 (train). The time used is 1.528s. \n",
      "At iter 556/1000, the losses are 1.51339 (train). The time used is 1.489s. \n",
      "At iter 557/1000, the losses are 1.51341 (train). The time used is 1.776s. \n",
      "At iter 558/1000, the losses are 1.51343 (train). The time used is 1.595s. \n",
      "At iter 559/1000, the losses are 1.51347 (train). The time used is 1.557s. \n",
      "At iter 560/1000, the losses are 1.51350 (train). The time used is 1.576s. \n",
      "====================================================================================================\n",
      "At iter 560/1000, the losses on all data are 0.84024. The time used is 0.569s. \n",
      "====================================================================================================\n",
      "At iter 561/1000, the losses are 1.51358 (train). The time used is 1.841s. \n",
      "At iter 562/1000, the losses are 1.51351 (train). The time used is 1.804s. \n",
      "At iter 563/1000, the losses are 1.51350 (train). The time used is 1.835s. \n",
      "At iter 564/1000, the losses are 1.51350 (train). The time used is 1.834s. \n",
      "At iter 565/1000, the losses are 1.51347 (train). The time used is 1.812s. \n",
      "At iter 566/1000, the losses are 1.51335 (train). The time used is 1.587s. \n",
      "At iter 567/1000, the losses are 1.51323 (train). The time used is 1.500s. \n",
      "At iter 568/1000, the losses are 1.51318 (train). The time used is 1.502s. \n",
      "At iter 569/1000, the losses are 1.51321 (train). The time used is 1.503s. \n",
      "At iter 570/1000, the losses are 1.51326 (train). The time used is 1.518s. \n",
      "At iter 571/1000, the losses are 1.51329 (train). The time used is 1.488s. \n",
      "At iter 572/1000, the losses are 1.51324 (train). The time used is 1.506s. \n",
      "At iter 573/1000, the losses are 1.51323 (train). The time used is 1.528s. \n",
      "At iter 574/1000, the losses are 1.51321 (train). The time used is 1.487s. \n",
      "At iter 575/1000, the losses are 1.51328 (train). The time used is 1.491s. \n",
      "At iter 576/1000, the losses are 1.51329 (train). The time used is 1.487s. \n",
      "At iter 577/1000, the losses are 1.51322 (train). The time used is 1.484s. \n",
      "At iter 578/1000, the losses are 1.51308 (train). The time used is 1.482s. \n",
      "At iter 579/1000, the losses are 1.51300 (train). The time used is 1.509s. \n",
      "At iter 580/1000, the losses are 1.51297 (train). The time used is 1.491s. \n",
      "====================================================================================================\n",
      "At iter 580/1000, the losses on all data are 0.84040. The time used is 0.500s. \n",
      "====================================================================================================\n",
      "At iter 581/1000, the losses are 1.51297 (train). The time used is 1.489s. \n",
      "At iter 582/1000, the losses are 1.51297 (train). The time used is 1.504s. \n",
      "At iter 583/1000, the losses are 1.51295 (train). The time used is 1.488s. \n",
      "At iter 584/1000, the losses are 1.51293 (train). The time used is 1.484s. \n",
      "At iter 585/1000, the losses are 1.51294 (train). The time used is 1.581s. \n",
      "At iter 586/1000, the losses are 1.51304 (train). The time used is 1.553s. \n",
      "At iter 587/1000, the losses are 1.51308 (train). The time used is 1.564s. \n",
      "At iter 588/1000, the losses are 1.51311 (train). The time used is 1.579s. \n",
      "At iter 589/1000, the losses are 1.51296 (train). The time used is 1.553s. \n",
      "At iter 590/1000, the losses are 1.51285 (train). The time used is 1.484s. \n",
      "At iter 591/1000, the losses are 1.51276 (train). The time used is 1.486s. \n",
      "At iter 592/1000, the losses are 1.51275 (train). The time used is 1.512s. \n",
      "At iter 593/1000, the losses are 1.51280 (train). The time used is 1.482s. \n",
      "At iter 594/1000, the losses are 1.51286 (train). The time used is 1.632s. \n",
      "At iter 595/1000, the losses are 1.51294 (train). The time used is 1.861s. \n",
      "At iter 596/1000, the losses are 1.51289 (train). The time used is 1.775s. \n",
      "At iter 597/1000, the losses are 1.51284 (train). The time used is 1.487s. \n",
      "At iter 598/1000, the losses are 1.51271 (train). The time used is 1.517s. \n",
      "At iter 599/1000, the losses are 1.51264 (train). The time used is 1.484s. \n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "At iter 600/1000, the losses are 1.51262 (train). The time used is 1.532s. \n",
      "====================================================================================================\n",
      "At iter 600/1000, the losses on all data are 0.84047. The time used is 0.626s. \n",
      "====================================================================================================\n",
      "At iter 601/1000, the losses are 1.51266 (train). The time used is 1.877s. \n",
      "At iter 602/1000, the losses are 1.51257 (train). The time used is 1.856s. \n",
      "At iter 603/1000, the losses are 1.51262 (train). The time used is 1.858s. \n",
      "At iter 604/1000, the losses are 1.51255 (train). The time used is 1.956s. \n",
      "At iter 605/1000, the losses are 1.51260 (train). The time used is 1.855s. \n",
      "At iter 606/1000, the losses are 1.51253 (train). The time used is 1.887s. \n",
      "At iter 607/1000, the losses are 1.51257 (train). The time used is 1.874s. \n",
      "At iter 608/1000, the losses are 1.51251 (train). The time used is 1.845s. \n",
      "At iter 609/1000, the losses are 1.51254 (train). The time used is 1.873s. \n",
      "At iter 610/1000, the losses are 1.51249 (train). The time used is 1.863s. \n",
      "At iter 611/1000, the losses are 1.51251 (train). The time used is 1.884s. \n",
      "At iter 612/1000, the losses are 1.51247 (train). The time used is 1.857s. \n",
      "At iter 613/1000, the losses are 1.51249 (train). The time used is 1.837s. \n",
      "At iter 614/1000, the losses are 1.51246 (train). The time used is 1.894s. \n",
      "At iter 615/1000, the losses are 1.51246 (train). The time used is 1.859s. \n",
      "At iter 616/1000, the losses are 1.51244 (train). The time used is 1.864s. \n",
      "At iter 617/1000, the losses are 1.51244 (train). The time used is 1.942s. \n",
      "At iter 618/1000, the losses are 1.51242 (train). The time used is 1.866s. \n",
      "At iter 619/1000, the losses are 1.51242 (train). The time used is 1.920s. \n",
      "At iter 620/1000, the losses are 1.51240 (train). The time used is 1.842s. \n",
      "====================================================================================================\n",
      "At iter 620/1000, the losses on all data are 0.84043. The time used is 0.581s. \n",
      "====================================================================================================\n",
      "At iter 621/1000, the losses are 1.51240 (train). The time used is 1.821s. \n",
      "At iter 622/1000, the losses are 1.51238 (train). The time used is 1.812s. \n",
      "At iter 623/1000, the losses are 1.51238 (train). The time used is 1.813s. \n",
      "At iter 624/1000, the losses are 1.51236 (train). The time used is 1.862s. \n",
      "At iter 625/1000, the losses are 1.51236 (train). The time used is 1.816s. \n",
      "At iter 626/1000, the losses are 1.51235 (train). The time used is 1.797s. \n",
      "At iter 627/1000, the losses are 1.51233 (train). The time used is 1.618s. \n",
      "At iter 628/1000, the losses are 1.51233 (train). The time used is 1.532s. \n",
      "At iter 629/1000, the losses are 1.51232 (train). The time used is 1.497s. \n",
      "At iter 630/1000, the losses are 1.51231 (train). The time used is 1.511s. \n",
      "At iter 631/1000, the losses are 1.51230 (train). The time used is 1.569s. \n",
      "At iter 632/1000, the losses are 1.51229 (train). The time used is 1.548s. \n",
      "At iter 633/1000, the losses are 1.51228 (train). The time used is 1.546s. \n",
      "At iter 634/1000, the losses are 1.51227 (train). The time used is 1.572s. \n",
      "At iter 635/1000, the losses are 1.51226 (train). The time used is 1.563s. \n",
      "At iter 636/1000, the losses are 1.51225 (train). The time used is 1.582s. \n",
      "At iter 637/1000, the losses are 1.51224 (train). The time used is 1.820s. \n",
      "At iter 638/1000, the losses are 1.51223 (train). The time used is 1.854s. \n",
      "At iter 639/1000, the losses are 1.51223 (train). The time used is 1.571s. \n",
      "At iter 640/1000, the losses are 1.51222 (train). The time used is 1.542s. \n",
      "====================================================================================================\n",
      "At iter 640/1000, the losses on all data are 0.84044. The time used is 0.491s. \n",
      "====================================================================================================\n",
      "At iter 641/1000, the losses are 1.51221 (train). The time used is 1.491s. \n",
      "At iter 642/1000, the losses are 1.51220 (train). The time used is 1.498s. \n",
      "At iter 643/1000, the losses are 1.51219 (train). The time used is 1.502s. \n",
      "At iter 644/1000, the losses are 1.51218 (train). The time used is 1.516s. \n",
      "At iter 645/1000, the losses are 1.51217 (train). The time used is 1.491s. \n",
      "At iter 646/1000, the losses are 1.51216 (train). The time used is 1.536s. \n",
      "At iter 647/1000, the losses are 1.51216 (train). The time used is 1.487s. \n",
      "At iter 648/1000, the losses are 1.51215 (train). The time used is 1.502s. \n",
      "At iter 649/1000, the losses are 1.51214 (train). The time used is 1.513s. \n",
      "At iter 650/1000, the losses are 1.51212 (train). The time used is 1.502s. \n",
      "At iter 651/1000, the losses are 1.51212 (train). The time used is 1.572s. \n",
      "At iter 652/1000, the losses are 1.51211 (train). The time used is 1.569s. \n",
      "At iter 653/1000, the losses are 1.51211 (train). The time used is 1.569s. \n",
      "At iter 654/1000, the losses are 1.51209 (train). The time used is 1.593s. \n",
      "At iter 655/1000, the losses are 1.51208 (train). The time used is 1.650s. \n",
      "At iter 656/1000, the losses are 1.51207 (train). The time used is 1.843s. \n",
      "At iter 657/1000, the losses are 1.51207 (train). The time used is 1.751s. \n",
      "At iter 658/1000, the losses are 1.51206 (train). The time used is 1.851s. \n",
      "At iter 659/1000, the losses are 1.51205 (train). The time used is 1.806s. \n",
      "At iter 660/1000, the losses are 1.51204 (train). The time used is 1.900s. \n",
      "====================================================================================================\n",
      "At iter 660/1000, the losses on all data are 0.84045. The time used is 0.628s. \n",
      "====================================================================================================\n",
      "At iter 661/1000, the losses are 1.51203 (train). The time used is 1.861s. \n",
      "At iter 662/1000, the losses are 1.51202 (train). The time used is 1.831s. \n",
      "At iter 663/1000, the losses are 1.51201 (train). The time used is 1.834s. \n",
      "At iter 664/1000, the losses are 1.51201 (train). The time used is 1.871s. \n",
      "At iter 665/1000, the losses are 1.51200 (train). The time used is 1.809s. \n",
      "At iter 666/1000, the losses are 1.51199 (train). The time used is 1.836s. \n",
      "At iter 667/1000, the losses are 1.51198 (train). The time used is 1.862s. \n",
      "At iter 668/1000, the losses are 1.51197 (train). The time used is 1.803s. \n",
      "At iter 669/1000, the losses are 1.51196 (train). The time used is 1.813s. \n",
      "At iter 670/1000, the losses are 1.51196 (train). The time used is 1.805s. \n",
      "At iter 671/1000, the losses are 1.51195 (train). The time used is 1.750s. \n",
      "At iter 672/1000, the losses are 1.51195 (train). The time used is 1.588s. \n",
      "At iter 673/1000, the losses are 1.51193 (train). The time used is 1.495s. \n",
      "At iter 674/1000, the losses are 1.51192 (train). The time used is 1.485s. \n",
      "At iter 675/1000, the losses are 1.51191 (train). The time used is 1.571s. \n",
      "At iter 676/1000, the losses are 1.51190 (train). The time used is 1.507s. \n",
      "At iter 677/1000, the losses are 1.51189 (train). The time used is 1.498s. \n",
      "At iter 678/1000, the losses are 1.51188 (train). The time used is 1.556s. \n",
      "At iter 679/1000, the losses are 1.51188 (train). The time used is 1.580s. \n",
      "At iter 680/1000, the losses are 1.51188 (train). The time used is 1.573s. \n",
      "====================================================================================================\n",
      "At iter 680/1000, the losses on all data are 0.84043. The time used is 0.495s. \n",
      "====================================================================================================\n",
      "At iter 681/1000, the losses are 1.51187 (train). The time used is 1.780s. \n",
      "At iter 682/1000, the losses are 1.51185 (train). The time used is 1.799s. \n",
      "At iter 683/1000, the losses are 1.51184 (train). The time used is 1.808s. \n",
      "At iter 684/1000, the losses are 1.51183 (train). The time used is 1.861s. \n",
      "At iter 685/1000, the losses are 1.51183 (train). The time used is 1.592s. \n",
      "At iter 686/1000, the losses are 1.51183 (train). The time used is 1.529s. \n",
      "At iter 687/1000, the losses are 1.51181 (train). The time used is 1.494s. \n",
      "At iter 688/1000, the losses are 1.51180 (train). The time used is 1.480s. \n",
      "At iter 689/1000, the losses are 1.51179 (train). The time used is 1.555s. \n",
      "At iter 690/1000, the losses are 1.51178 (train). The time used is 1.580s. \n",
      "At iter 691/1000, the losses are 1.51177 (train). The time used is 1.555s. \n",
      "At iter 692/1000, the losses are 1.51177 (train). The time used is 1.553s. \n",
      "At iter 693/1000, the losses are 1.51177 (train). The time used is 1.546s. \n",
      "At iter 694/1000, the losses are 1.51175 (train). The time used is 1.513s. \n",
      "At iter 695/1000, the losses are 1.51173 (train). The time used is 1.511s. \n",
      "At iter 696/1000, the losses are 1.51172 (train). The time used is 1.531s. \n",
      "At iter 697/1000, the losses are 1.51172 (train). The time used is 1.582s. \n",
      "At iter 698/1000, the losses are 1.51171 (train). The time used is 1.970s. \n",
      "At iter 699/1000, the losses are 1.51171 (train). The time used is 1.880s. \n",
      "At iter 700/1000, the losses are 1.51171 (train). The time used is 1.829s. \n",
      "====================================================================================================\n",
      "At iter 700/1000, the losses on all data are 0.84048. The time used is 0.613s. \n",
      "====================================================================================================\n",
      "At iter 701/1000, the losses are 1.51169 (train). The time used is 1.773s. \n",
      "At iter 702/1000, the losses are 1.51168 (train). The time used is 1.806s. \n",
      "At iter 703/1000, the losses are 1.51166 (train). The time used is 1.864s. \n",
      "At iter 704/1000, the losses are 1.51166 (train). The time used is 1.789s. \n",
      "At iter 705/1000, the losses are 1.51166 (train). The time used is 1.809s. \n",
      "At iter 706/1000, the losses are 1.51166 (train). The time used is 1.783s. \n",
      "At iter 707/1000, the losses are 1.51165 (train). The time used is 1.777s. \n",
      "At iter 708/1000, the losses are 1.51162 (train). The time used is 1.763s. \n",
      "At iter 709/1000, the losses are 1.51161 (train). The time used is 1.763s. \n",
      "At iter 710/1000, the losses are 1.51161 (train). The time used is 1.858s. \n",
      "At iter 711/1000, the losses are 1.51161 (train). The time used is 1.710s. \n",
      "At iter 712/1000, the losses are 1.51160 (train). The time used is 1.549s. \n",
      "At iter 713/1000, the losses are 1.51158 (train). The time used is 1.547s. \n",
      "At iter 714/1000, the losses are 1.51157 (train). The time used is 1.549s. \n",
      "At iter 715/1000, the losses are 1.51156 (train). The time used is 1.563s. \n",
      "At iter 716/1000, the losses are 1.51156 (train). The time used is 1.570s. \n",
      "At iter 717/1000, the losses are 1.51156 (train). The time used is 1.590s. \n",
      "At iter 718/1000, the losses are 1.51155 (train). The time used is 1.589s. \n",
      "At iter 719/1000, the losses are 1.51153 (train). The time used is 1.511s. \n",
      "At iter 720/1000, the losses are 1.51152 (train). The time used is 1.494s. \n",
      "====================================================================================================\n",
      "At iter 720/1000, the losses on all data are 0.84046. The time used is 0.494s. \n",
      "====================================================================================================\n",
      "At iter 721/1000, the losses are 1.51151 (train). The time used is 1.488s. \n",
      "At iter 722/1000, the losses are 1.51150 (train). The time used is 1.510s. \n",
      "At iter 723/1000, the losses are 1.51149 (train). The time used is 1.491s. \n",
      "At iter 724/1000, the losses are 1.51149 (train). The time used is 1.506s. \n",
      "At iter 725/1000, the losses are 1.51149 (train). The time used is 1.584s. \n",
      "At iter 726/1000, the losses are 1.51148 (train). The time used is 1.822s. \n",
      "At iter 727/1000, the losses are 1.51147 (train). The time used is 1.814s. \n",
      "At iter 728/1000, the losses are 1.51146 (train). The time used is 1.885s. \n",
      "At iter 729/1000, the losses are 1.51144 (train). The time used is 1.812s. \n",
      "At iter 730/1000, the losses are 1.51143 (train). The time used is 1.802s. \n",
      "At iter 731/1000, the losses are 1.51142 (train). The time used is 1.853s. \n",
      "At iter 732/1000, the losses are 1.51143 (train). The time used is 1.804s. \n",
      "At iter 733/1000, the losses are 1.51142 (train). The time used is 1.906s. \n",
      "At iter 734/1000, the losses are 1.51140 (train). The time used is 1.781s. \n",
      "At iter 735/1000, the losses are 1.51138 (train). The time used is 1.761s. \n",
      "At iter 736/1000, the losses are 1.51138 (train). The time used is 1.848s. \n",
      "At iter 737/1000, the losses are 1.51138 (train). The time used is 1.795s. \n",
      "At iter 738/1000, the losses are 1.51139 (train). The time used is 1.814s. \n",
      "At iter 739/1000, the losses are 1.51137 (train). The time used is 1.829s. \n",
      "At iter 740/1000, the losses are 1.51134 (train). The time used is 1.657s. \n",
      "====================================================================================================\n",
      "At iter 740/1000, the losses on all data are 0.84046. The time used is 0.490s. \n",
      "====================================================================================================\n",
      "At iter 741/1000, the losses are 1.51134 (train). The time used is 1.481s. \n",
      "At iter 742/1000, the losses are 1.51134 (train). The time used is 1.794s. \n",
      "At iter 743/1000, the losses are 1.51135 (train). The time used is 1.844s. \n",
      "At iter 744/1000, the losses are 1.51132 (train). The time used is 1.918s. \n",
      "At iter 745/1000, the losses are 1.51130 (train). The time used is 1.839s. \n",
      "At iter 746/1000, the losses are 1.51130 (train). The time used is 1.853s. \n",
      "At iter 747/1000, the losses are 1.51129 (train). The time used is 1.859s. \n",
      "At iter 748/1000, the losses are 1.51129 (train). The time used is 1.790s. \n",
      "At iter 749/1000, the losses are 1.51127 (train). The time used is 1.762s. \n",
      "At iter 750/1000, the losses are 1.51125 (train). The time used is 1.809s. \n",
      "At iter 751/1000, the losses are 1.51127 (train). The time used is 1.802s. \n",
      "At iter 752/1000, the losses are 1.51127 (train). The time used is 1.809s. \n",
      "At iter 753/1000, the losses are 1.51125 (train). The time used is 1.768s. \n",
      "At iter 754/1000, the losses are 1.51122 (train). The time used is 1.485s. \n",
      "At iter 755/1000, the losses are 1.51122 (train). The time used is 1.737s. \n",
      "At iter 756/1000, the losses are 1.51124 (train). The time used is 1.879s. \n",
      "At iter 757/1000, the losses are 1.51123 (train). The time used is 1.841s. \n",
      "At iter 758/1000, the losses are 1.51119 (train). The time used is 1.938s. \n",
      "At iter 759/1000, the losses are 1.51118 (train). The time used is 1.845s. \n",
      "At iter 760/1000, the losses are 1.51118 (train). The time used is 1.795s. \n",
      "====================================================================================================\n",
      "At iter 760/1000, the losses on all data are 0.84043. The time used is 0.632s. \n",
      "====================================================================================================\n",
      "At iter 761/1000, the losses are 1.51119 (train). The time used is 1.795s. \n",
      "At iter 762/1000, the losses are 1.51116 (train). The time used is 1.789s. \n",
      "At iter 763/1000, the losses are 1.51114 (train). The time used is 1.870s. \n",
      "At iter 764/1000, the losses are 1.51114 (train). The time used is 1.583s. \n",
      "At iter 765/1000, the losses are 1.51114 (train). The time used is 1.520s. \n",
      "At iter 766/1000, the losses are 1.51114 (train). The time used is 1.501s. \n",
      "At iter 767/1000, the losses are 1.51112 (train). The time used is 1.494s. \n",
      "At iter 768/1000, the losses are 1.51110 (train). The time used is 1.493s. \n",
      "At iter 769/1000, the losses are 1.51109 (train). The time used is 1.482s. \n",
      "At iter 770/1000, the losses are 1.51108 (train). The time used is 1.535s. \n",
      "At iter 771/1000, the losses are 1.51108 (train). The time used is 1.499s. \n",
      "At iter 772/1000, the losses are 1.51107 (train). The time used is 1.495s. \n",
      "At iter 773/1000, the losses are 1.51106 (train). The time used is 1.538s. \n",
      "At iter 774/1000, the losses are 1.51105 (train). The time used is 1.493s. \n",
      "At iter 775/1000, the losses are 1.51104 (train). The time used is 1.479s. \n",
      "At iter 776/1000, the losses are 1.51103 (train). The time used is 1.524s. \n",
      "At iter 777/1000, the losses are 1.51102 (train). The time used is 1.534s. \n",
      "At iter 778/1000, the losses are 1.51101 (train). The time used is 1.492s. \n",
      "At iter 779/1000, the losses are 1.51100 (train). The time used is 1.506s. \n",
      "At iter 780/1000, the losses are 1.51099 (train). The time used is 1.493s. \n",
      "====================================================================================================\n",
      "At iter 780/1000, the losses on all data are 0.84049. The time used is 0.506s. \n",
      "====================================================================================================\n",
      "At iter 781/1000, the losses are 1.51098 (train). The time used is 1.483s. \n",
      "At iter 782/1000, the losses are 1.51098 (train). The time used is 1.488s. \n",
      "At iter 783/1000, the losses are 1.51098 (train). The time used is 1.565s. \n",
      "At iter 784/1000, the losses are 1.51100 (train). The time used is 1.507s. \n",
      "At iter 785/1000, the losses are 1.51097 (train). The time used is 1.482s. \n",
      "At iter 786/1000, the losses are 1.51095 (train). The time used is 1.542s. \n",
      "At iter 787/1000, the losses are 1.51093 (train). The time used is 1.777s. \n",
      "At iter 788/1000, the losses are 1.51092 (train). The time used is 1.584s. \n",
      "At iter 789/1000, the losses are 1.51091 (train). The time used is 1.528s. \n",
      "At iter 790/1000, the losses are 1.51090 (train). The time used is 1.552s. \n",
      "At iter 791/1000, the losses are 1.51091 (train). The time used is 1.504s. \n",
      "At iter 792/1000, the losses are 1.51092 (train). The time used is 1.498s. \n",
      "At iter 793/1000, the losses are 1.51091 (train). The time used is 1.486s. \n",
      "At iter 794/1000, the losses are 1.51088 (train). The time used is 1.747s. \n",
      "At iter 795/1000, the losses are 1.51086 (train). The time used is 1.811s. \n",
      "At iter 796/1000, the losses are 1.51085 (train). The time used is 1.830s. \n",
      "At iter 797/1000, the losses are 1.51084 (train). The time used is 1.849s. \n",
      "At iter 798/1000, the losses are 1.51083 (train). The time used is 1.505s. \n",
      "At iter 799/1000, the losses are 1.51084 (train). The time used is 1.518s. \n",
      "At iter 800/1000, the losses are 1.51085 (train). The time used is 1.586s. \n",
      "====================================================================================================\n",
      "At iter 800/1000, the losses on all data are 0.84052. The time used is 0.493s. \n",
      "====================================================================================================\n",
      "At iter 801/1000, the losses are 1.51084 (train). The time used is 1.490s. \n",
      "At iter 802/1000, the losses are 1.51082 (train). The time used is 1.558s. \n",
      "At iter 803/1000, the losses are 1.51079 (train). The time used is 1.485s. \n",
      "At iter 804/1000, the losses are 1.51078 (train). The time used is 1.484s. \n",
      "At iter 805/1000, the losses are 1.51077 (train). The time used is 1.535s. \n",
      "At iter 806/1000, the losses are 1.51076 (train). The time used is 1.517s. \n",
      "At iter 807/1000, the losses are 1.51075 (train). The time used is 1.521s. \n",
      "At iter 808/1000, the losses are 1.51075 (train). The time used is 1.595s. \n",
      "At iter 809/1000, the losses are 1.51076 (train). The time used is 1.497s. \n",
      "At iter 810/1000, the losses are 1.51076 (train). The time used is 1.583s. \n",
      "At iter 811/1000, the losses are 1.51074 (train). The time used is 1.567s. \n",
      "At iter 812/1000, the losses are 1.51071 (train). The time used is 1.572s. \n",
      "At iter 813/1000, the losses are 1.51070 (train). The time used is 1.572s. \n",
      "At iter 814/1000, the losses are 1.51069 (train). The time used is 1.587s. \n",
      "At iter 815/1000, the losses are 1.51068 (train). The time used is 1.579s. \n",
      "At iter 816/1000, the losses are 1.51067 (train). The time used is 1.506s. \n",
      "At iter 817/1000, the losses are 1.51066 (train). The time used is 1.501s. \n",
      "At iter 818/1000, the losses are 1.51065 (train). The time used is 1.647s. \n",
      "At iter 819/1000, the losses are 1.51065 (train). The time used is 1.804s. \n",
      "At iter 820/1000, the losses are 1.51066 (train). The time used is 1.811s. \n",
      "====================================================================================================\n",
      "At iter 820/1000, the losses on all data are 0.84054. The time used is 0.625s. \n",
      "====================================================================================================\n",
      "At iter 821/1000, the losses are 1.51067 (train). The time used is 1.783s. \n",
      "At iter 822/1000, the losses are 1.51065 (train). The time used is 1.805s. \n",
      "At iter 823/1000, the losses are 1.51062 (train). The time used is 1.854s. \n",
      "At iter 824/1000, the losses are 1.51060 (train). The time used is 1.628s. \n",
      "At iter 825/1000, the losses are 1.51059 (train). The time used is 1.560s. \n",
      "At iter 826/1000, the losses are 1.51058 (train). The time used is 1.568s. \n",
      "At iter 827/1000, the losses are 1.51058 (train). The time used is 1.585s. \n",
      "At iter 828/1000, the losses are 1.51059 (train). The time used is 1.551s. \n",
      "At iter 829/1000, the losses are 1.51059 (train). The time used is 1.488s. \n",
      "At iter 830/1000, the losses are 1.51058 (train). The time used is 1.508s. \n",
      "At iter 831/1000, the losses are 1.51055 (train). The time used is 1.567s. \n",
      "At iter 832/1000, the losses are 1.51053 (train). The time used is 1.571s. \n",
      "At iter 833/1000, the losses are 1.51052 (train). The time used is 1.565s. \n",
      "At iter 834/1000, the losses are 1.51051 (train). The time used is 1.569s. \n",
      "At iter 835/1000, the losses are 1.51050 (train). The time used is 1.529s. \n",
      "At iter 836/1000, the losses are 1.51049 (train). The time used is 1.506s. \n",
      "At iter 837/1000, the losses are 1.51049 (train). The time used is 1.554s. \n",
      "At iter 838/1000, the losses are 1.51048 (train). The time used is 1.518s. \n",
      "At iter 839/1000, the losses are 1.51049 (train). The time used is 1.489s. \n",
      "At iter 840/1000, the losses are 1.51050 (train). The time used is 1.728s. \n",
      "====================================================================================================\n",
      "At iter 840/1000, the losses on all data are 0.84045. The time used is 0.616s. \n",
      "====================================================================================================\n",
      "At iter 841/1000, the losses are 1.51049 (train). The time used is 1.871s. \n",
      "At iter 842/1000, the losses are 1.51046 (train). The time used is 1.583s. \n",
      "At iter 843/1000, the losses are 1.51045 (train). The time used is 1.551s. \n",
      "At iter 844/1000, the losses are 1.51043 (train). The time used is 1.804s. \n",
      "At iter 845/1000, the losses are 1.51042 (train). The time used is 1.803s. \n",
      "At iter 846/1000, the losses are 1.51042 (train). The time used is 1.762s. \n",
      "At iter 847/1000, the losses are 1.51042 (train). The time used is 1.538s. \n",
      "At iter 848/1000, the losses are 1.51042 (train). The time used is 1.559s. \n",
      "At iter 849/1000, the losses are 1.51041 (train). The time used is 1.502s. \n",
      "At iter 850/1000, the losses are 1.51039 (train). The time used is 1.495s. \n",
      "At iter 851/1000, the losses are 1.51037 (train). The time used is 1.715s. \n",
      "At iter 852/1000, the losses are 1.51036 (train). The time used is 1.537s. \n",
      "At iter 853/1000, the losses are 1.51035 (train). The time used is 1.513s. \n",
      "At iter 854/1000, the losses are 1.51034 (train). The time used is 1.527s. \n",
      "At iter 855/1000, the losses are 1.51033 (train). The time used is 1.555s. \n",
      "At iter 856/1000, the losses are 1.51032 (train). The time used is 1.556s. \n",
      "At iter 857/1000, the losses are 1.51031 (train). The time used is 1.579s. \n",
      "At iter 858/1000, the losses are 1.51030 (train). The time used is 1.807s. \n",
      "At iter 859/1000, the losses are 1.51029 (train). The time used is 1.854s. \n",
      "At iter 860/1000, the losses are 1.51028 (train). The time used is 1.814s. \n",
      "====================================================================================================\n",
      "At iter 860/1000, the losses on all data are 0.84048. The time used is 0.619s. \n",
      "====================================================================================================\n",
      "At iter 861/1000, the losses are 1.51029 (train). The time used is 1.804s. \n",
      "At iter 862/1000, the losses are 1.51031 (train). The time used is 1.797s. \n",
      "At iter 863/1000, the losses are 1.51033 (train). The time used is 1.803s. \n",
      "At iter 864/1000, the losses are 1.51028 (train). The time used is 1.877s. \n",
      "At iter 865/1000, the losses are 1.51025 (train). The time used is 1.663s. \n",
      "At iter 866/1000, the losses are 1.51023 (train). The time used is 1.546s. \n",
      "At iter 867/1000, the losses are 1.51022 (train). The time used is 1.566s. \n",
      "At iter 868/1000, the losses are 1.51021 (train). The time used is 1.781s. \n",
      "At iter 869/1000, the losses are 1.51020 (train). The time used is 1.813s. \n",
      "At iter 870/1000, the losses are 1.51020 (train). The time used is 1.801s. \n",
      "At iter 871/1000, the losses are 1.51020 (train). The time used is 1.855s. \n",
      "At iter 872/1000, the losses are 1.51022 (train). The time used is 1.755s. \n",
      "At iter 873/1000, the losses are 1.51024 (train). The time used is 1.478s. \n",
      "At iter 874/1000, the losses are 1.51020 (train). The time used is 1.503s. \n",
      "At iter 875/1000, the losses are 1.51017 (train). The time used is 1.543s. \n",
      "At iter 876/1000, the losses are 1.51014 (train). The time used is 1.487s. \n",
      "At iter 877/1000, the losses are 1.51013 (train). The time used is 1.500s. \n",
      "At iter 878/1000, the losses are 1.51013 (train). The time used is 1.570s. \n",
      "At iter 879/1000, the losses are 1.51015 (train). The time used is 1.578s. \n",
      "At iter 880/1000, the losses are 1.51018 (train). The time used is 1.497s. \n",
      "====================================================================================================\n",
      "At iter 880/1000, the losses on all data are 0.84056. The time used is 0.489s. \n",
      "====================================================================================================\n",
      "At iter 881/1000, the losses are 1.51015 (train). The time used is 1.541s. \n",
      "At iter 882/1000, the losses are 1.51011 (train). The time used is 1.620s. \n",
      "At iter 883/1000, the losses are 1.51008 (train). The time used is 1.486s. \n",
      "At iter 884/1000, the losses are 1.51008 (train). The time used is 1.482s. \n",
      "At iter 885/1000, the losses are 1.51008 (train). The time used is 1.501s. \n",
      "At iter 886/1000, the losses are 1.51011 (train). The time used is 1.486s. \n",
      "At iter 887/1000, the losses are 1.51011 (train). The time used is 1.553s. \n",
      "At iter 888/1000, the losses are 1.51007 (train). The time used is 1.518s. \n",
      "At iter 889/1000, the losses are 1.51004 (train). The time used is 1.531s. \n",
      "At iter 890/1000, the losses are 1.51003 (train). The time used is 1.607s. \n",
      "At iter 891/1000, the losses are 1.51003 (train). The time used is 1.555s. \n",
      "At iter 892/1000, the losses are 1.51002 (train). The time used is 1.490s. \n",
      "At iter 893/1000, the losses are 1.51001 (train). The time used is 1.752s. \n",
      "At iter 894/1000, the losses are 1.50999 (train). The time used is 1.790s. \n",
      "At iter 895/1000, the losses are 1.50999 (train). The time used is 1.623s. \n",
      "At iter 896/1000, the losses are 1.51001 (train). The time used is 1.491s. \n",
      "At iter 897/1000, the losses are 1.51001 (train). The time used is 1.694s. \n",
      "At iter 898/1000, the losses are 1.50998 (train). The time used is 1.876s. \n",
      "At iter 899/1000, the losses are 1.50995 (train). The time used is 1.800s. \n",
      "Adjusting learning rate of group 0 to 2.5000e-05.\n",
      "At iter 900/1000, the losses are 1.50993 (train). The time used is 1.891s. \n",
      "====================================================================================================\n",
      "At iter 900/1000, the losses on all data are 0.84052. The time used is 0.646s. \n",
      "====================================================================================================\n",
      "At iter 901/1000, the losses are 1.50992 (train). The time used is 1.827s. \n",
      "At iter 902/1000, the losses are 1.50991 (train). The time used is 1.808s. \n",
      "At iter 903/1000, the losses are 1.50991 (train). The time used is 1.808s. \n",
      "At iter 904/1000, the losses are 1.50990 (train). The time used is 1.797s. \n",
      "At iter 905/1000, the losses are 1.50990 (train). The time used is 1.843s. \n",
      "At iter 906/1000, the losses are 1.50989 (train). The time used is 1.795s. \n",
      "At iter 907/1000, the losses are 1.50989 (train). The time used is 1.578s. \n",
      "At iter 908/1000, the losses are 1.50988 (train). The time used is 1.498s. \n",
      "At iter 909/1000, the losses are 1.50988 (train). The time used is 1.561s. \n",
      "At iter 910/1000, the losses are 1.50987 (train). The time used is 1.522s. \n",
      "At iter 911/1000, the losses are 1.50987 (train). The time used is 1.500s. \n",
      "At iter 912/1000, the losses are 1.50986 (train). The time used is 1.519s. \n",
      "At iter 913/1000, the losses are 1.50986 (train). The time used is 1.562s. \n",
      "At iter 914/1000, the losses are 1.50985 (train). The time used is 1.553s. \n",
      "At iter 915/1000, the losses are 1.50985 (train). The time used is 1.504s. \n",
      "At iter 916/1000, the losses are 1.50984 (train). The time used is 1.513s. \n",
      "At iter 917/1000, the losses are 1.50984 (train). The time used is 1.565s. \n",
      "At iter 918/1000, the losses are 1.50983 (train). The time used is 1.560s. \n",
      "At iter 919/1000, the losses are 1.50983 (train). The time used is 1.517s. \n",
      "At iter 920/1000, the losses are 1.50983 (train). The time used is 1.490s. \n",
      "====================================================================================================\n",
      "At iter 920/1000, the losses on all data are 0.84051. The time used is 0.494s. \n",
      "====================================================================================================\n",
      "At iter 921/1000, the losses are 1.50982 (train). The time used is 1.488s. \n",
      "At iter 922/1000, the losses are 1.50982 (train). The time used is 1.790s. \n",
      "At iter 923/1000, the losses are 1.50981 (train). The time used is 1.763s. \n",
      "At iter 924/1000, the losses are 1.50981 (train). The time used is 1.896s. \n",
      "At iter 925/1000, the losses are 1.50980 (train). The time used is 1.815s. \n",
      "At iter 926/1000, the losses are 1.50980 (train). The time used is 1.889s. \n",
      "At iter 927/1000, the losses are 1.50979 (train). The time used is 1.804s. \n",
      "At iter 928/1000, the losses are 1.50979 (train). The time used is 1.806s. \n",
      "At iter 929/1000, the losses are 1.50979 (train). The time used is 1.837s. \n",
      "At iter 930/1000, the losses are 1.50978 (train). The time used is 1.820s. \n",
      "At iter 931/1000, the losses are 1.50978 (train). The time used is 1.809s. \n",
      "At iter 932/1000, the losses are 1.50978 (train). The time used is 1.851s. \n",
      "At iter 933/1000, the losses are 1.50977 (train). The time used is 1.923s. \n",
      "At iter 934/1000, the losses are 1.50976 (train). The time used is 1.838s. \n",
      "At iter 935/1000, the losses are 1.50976 (train). The time used is 1.850s. \n",
      "At iter 936/1000, the losses are 1.50975 (train). The time used is 1.868s. \n",
      "At iter 937/1000, the losses are 1.50975 (train). The time used is 1.867s. \n",
      "At iter 938/1000, the losses are 1.50975 (train). The time used is 1.857s. \n",
      "At iter 939/1000, the losses are 1.50974 (train). The time used is 1.610s. \n",
      "At iter 940/1000, the losses are 1.50974 (train). The time used is 1.829s. \n",
      "====================================================================================================\n",
      "At iter 940/1000, the losses on all data are 0.84052. The time used is 0.617s. \n",
      "====================================================================================================\n",
      "At iter 941/1000, the losses are 1.50973 (train). The time used is 1.864s. \n",
      "At iter 942/1000, the losses are 1.50973 (train). The time used is 1.795s. \n",
      "At iter 943/1000, the losses are 1.50972 (train). The time used is 1.802s. \n",
      "At iter 944/1000, the losses are 1.50972 (train). The time used is 1.849s. \n",
      "At iter 945/1000, the losses are 1.50971 (train). The time used is 1.817s. \n",
      "At iter 946/1000, the losses are 1.50971 (train). The time used is 1.854s. \n",
      "At iter 947/1000, the losses are 1.50971 (train). The time used is 1.688s. \n",
      "At iter 948/1000, the losses are 1.50970 (train). The time used is 1.829s. \n",
      "At iter 949/1000, the losses are 1.50969 (train). The time used is 1.810s. \n",
      "At iter 950/1000, the losses are 1.50969 (train). The time used is 1.900s. \n",
      "At iter 951/1000, the losses are 1.50969 (train). The time used is 1.786s. \n",
      "At iter 952/1000, the losses are 1.50969 (train). The time used is 1.816s. \n",
      "At iter 953/1000, the losses are 1.50968 (train). The time used is 1.599s. \n",
      "At iter 954/1000, the losses are 1.50967 (train). The time used is 1.513s. \n",
      "At iter 955/1000, the losses are 1.50967 (train). The time used is 1.486s. \n",
      "At iter 956/1000, the losses are 1.50966 (train). The time used is 1.793s. \n",
      "At iter 957/1000, the losses are 1.50966 (train). The time used is 1.565s. \n",
      "At iter 958/1000, the losses are 1.50966 (train). The time used is 1.538s. \n",
      "At iter 959/1000, the losses are 1.50965 (train). The time used is 1.561s. \n",
      "At iter 960/1000, the losses are 1.50964 (train). The time used is 1.547s. \n",
      "====================================================================================================\n",
      "At iter 960/1000, the losses on all data are 0.84052. The time used is 0.493s. \n",
      "====================================================================================================\n",
      "At iter 961/1000, the losses are 1.50964 (train). The time used is 1.499s. \n",
      "At iter 962/1000, the losses are 1.50963 (train). The time used is 1.812s. \n",
      "At iter 963/1000, the losses are 1.50963 (train). The time used is 1.867s. \n",
      "At iter 964/1000, the losses are 1.50962 (train). The time used is 1.853s. \n",
      "At iter 965/1000, the losses are 1.50962 (train). The time used is 1.826s. \n",
      "At iter 966/1000, the losses are 1.50962 (train). The time used is 1.506s. \n",
      "At iter 967/1000, the losses are 1.50961 (train). The time used is 1.492s. \n",
      "At iter 968/1000, the losses are 1.50961 (train). The time used is 1.522s. \n",
      "At iter 969/1000, the losses are 1.50960 (train). The time used is 1.483s. \n",
      "At iter 970/1000, the losses are 1.50960 (train). The time used is 1.506s. \n",
      "At iter 971/1000, the losses are 1.50959 (train). The time used is 1.499s. \n",
      "At iter 972/1000, the losses are 1.50959 (train). The time used is 1.485s. \n",
      "At iter 973/1000, the losses are 1.50958 (train). The time used is 1.519s. \n",
      "At iter 974/1000, the losses are 1.50958 (train). The time used is 1.494s. \n",
      "At iter 975/1000, the losses are 1.50957 (train). The time used is 1.514s. \n",
      "At iter 976/1000, the losses are 1.50957 (train). The time used is 1.500s. \n",
      "At iter 977/1000, the losses are 1.50957 (train). The time used is 1.507s. \n",
      "At iter 978/1000, the losses are 1.50956 (train). The time used is 1.771s. \n",
      "At iter 979/1000, the losses are 1.50955 (train). The time used is 1.801s. \n",
      "At iter 980/1000, the losses are 1.50955 (train). The time used is 1.807s. \n",
      "====================================================================================================\n",
      "At iter 980/1000, the losses on all data are 0.84053. The time used is 0.630s. \n",
      "====================================================================================================\n",
      "At iter 981/1000, the losses are 1.50954 (train). The time used is 1.792s. \n",
      "At iter 982/1000, the losses are 1.50954 (train). The time used is 1.795s. \n",
      "At iter 983/1000, the losses are 1.50954 (train). The time used is 1.796s. \n",
      "At iter 984/1000, the losses are 1.50954 (train). The time used is 1.861s. \n",
      "At iter 985/1000, the losses are 1.50953 (train). The time used is 1.817s. \n",
      "At iter 986/1000, the losses are 1.50953 (train). The time used is 1.923s. \n",
      "At iter 987/1000, the losses are 1.50952 (train). The time used is 1.802s. \n",
      "At iter 988/1000, the losses are 1.50951 (train). The time used is 1.891s. \n",
      "At iter 989/1000, the losses are 1.50951 (train). The time used is 1.831s. \n",
      "At iter 990/1000, the losses are 1.50951 (train). The time used is 1.908s. \n",
      "At iter 991/1000, the losses are 1.50950 (train). The time used is 1.819s. \n",
      "At iter 992/1000, the losses are 1.50950 (train). The time used is 1.857s. \n",
      "At iter 993/1000, the losses are 1.50949 (train). The time used is 1.805s. \n",
      "At iter 994/1000, the losses are 1.50949 (train). The time used is 1.815s. \n",
      "At iter 995/1000, the losses are 1.50948 (train). The time used is 1.788s. \n",
      "At iter 996/1000, the losses are 1.50948 (train). The time used is 1.806s. \n",
      "At iter 997/1000, the losses are 1.50947 (train). The time used is 1.793s. \n",
      "At iter 998/1000, the losses are 1.50947 (train). The time used is 1.890s. \n",
      "At iter 999/1000, the losses are 1.50947 (train). The time used is 1.809s. \n",
      "At iter 1000/1000, the losses are 1.50946 (train). The time used is 1.782s. \n",
      "====================================================================================================\n",
      "At iter 1000/1000, the losses on all data are 0.84052. The time used is 0.652s. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_cur = 0\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "t0 = time.time()\n",
    "sgm_net.eval()\n",
    "loss_add = 0\n",
    "for ix in range(paras_rnn.niter):\n",
    "    rnn.train()\n",
    "    # Here because the whole dataset is not large, \n",
    "    # I use them as one batch\n",
    "    # Of course, you can use random_samples_rnn to draw \n",
    "    # X_seq = random_samples_rnn(all_data, \n",
    "    #                           batchsize=paras_rnn.batchsize)\n",
    "    X_seq = all_data_input\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    theta_pred = rnn(X_seq)\n",
    "    X_pred = sgm_net(theta_pred.flatten(0, 1))\n",
    "    loss_main = loss_fn(X_seq.flatten(0, 1).reshape(-1, 68, len(paras.freqs)),\n",
    "                   X_pred)\n",
    "    if paras_rnn.unstable_pen > 0:\n",
    "        unstable_inds = paras_stable_check(theta_pred.flatten(0, 1).detach().numpy());\n",
    "        unstable_inds = torch.tensor(unstable_inds).reshape(*theta_pred.shape[:2])\n",
    "        loss_add = (paras_rnn.unstable_pen * unstable_inds.unsqueeze(-1) * theta_pred).mean();\n",
    "    loss = loss_main + loss_add\n",
    "    \n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), paras_rnn.clip)\n",
    "    # Perform optimization\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ix % paras_rnn.lr_step == (paras_rnn.lr_step-1):\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss_cur = loss_cur + loss_main.item()\n",
    "    if ix % paras_rnn.loss_out == (paras_rnn.loss_out-1):\n",
    "        losses.append(loss_cur/paras_rnn.loss_out)\n",
    "        print(f\"At iter {ix+1}/{paras_rnn.niter}, \"\n",
    "              f\"the losses are {loss_cur/paras_rnn.loss_out:.5f} (train). \"\n",
    "              f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "             )\n",
    "        loss_cur = 0\n",
    "        t0 = time.time()\n",
    "        \n",
    "    if ix % paras_rnn.eval_out == (paras_rnn.eval_out-1):\n",
    "        rnn.eval()\n",
    "        loss_test = _evaluate(all_data).mean()\n",
    "        losses_test.append(loss_test)\n",
    "        print(f\"=\"*100)\n",
    "        print(f\"At iter {ix+1}/{paras_rnn.niter}, \"\n",
    "              f\"the losses on all data are {loss_test:.5f}. \"\n",
    "              f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "             )\n",
    "        print(f\"=\"*100)\n",
    "        t0 = time.time()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1147e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef8fc65",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8075a3b-5f07-41fd-a38b-fc022abd53eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:25:13.816449Z",
     "iopub.status.busy": "2024-01-05T03:25:13.816102Z",
     "iopub.status.idle": "2024-01-05T03:25:14.585789Z",
     "shell.execute_reply": "2024-01-05T03:25:14.584568Z",
     "shell.execute_reply.started": "2024-01-05T03:25:13.816431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse\n",
      "Create a folder /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/model.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss_fn.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/optimizer.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/paras.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss.pkl\n"
     ]
    }
   ],
   "source": [
    "if (paras_rnn.save_dir).exists():\n",
    "    trained_model = load_pkl_folder2dict(paras_rnn.save_dir)\n",
    "else:\n",
    "    trained_model = edict()\n",
    "    trained_model.model = rnn\n",
    "    trained_model.loss_fn = loss_fn\n",
    "    trained_model.optimizer = optimizer\n",
    "    trained_model.paras = paras_rnn\n",
    "    trained_model.loss = losses\n",
    "    save_pkl_dict2folder(paras_rnn.save_dir, trained_model, is_force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95b8d8-ed67-42b4-baac-8448f6cb203f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a978aa-d304-4743-871a-7c56d5e0a3e6",
   "metadata": {},
   "source": [
    "# PSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "043ff2fb-e467-4a8f-b576-01905f2cb496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:25:14.588041Z",
     "iopub.status.busy": "2024-01-05T03:25:14.587359Z",
     "iopub.status.idle": "2024-01-05T03:25:14.778305Z",
     "shell.execute_reply": "2024-01-05T03:25:14.777580Z",
     "shell.execute_reply.started": "2024-01-05T03:25:14.587993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss_fn.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/model.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/optimizer.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/paras.pkl\n"
     ]
    }
   ],
   "source": [
    "trained_model = load_pkl_folder2dict(paras_rnn.save_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554c2a17-cfe6-4a04-9190-149f1e1cff32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T03:25:14.780496Z",
     "iopub.status.busy": "2024-01-05T03:25:14.779721Z",
     "iopub.status.idle": "2024-01-05T03:25:14.954267Z",
     "shell.execute_reply": "2024-01-05T03:25:14.953653Z",
     "shell.execute_reply.started": "2024-01-05T03:25:14.780451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss_fn.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/model.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/optimizer.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/paras.pkl exists! Use is_force=True to save it anyway\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/sgm_paramss_est.pkl\n"
     ]
    }
   ],
   "source": [
    "trained_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_pred = trained_model.model(all_data_input)\n",
    "sgm_paramss_est = Y_pred.cpu().numpy().transpose(1, 0, 2)\n",
    "trained_model.sgm_paramss_est = sgm_paramss_est\n",
    "save_pkl_dict2folder(paras_rnn.save_dir, trained_model, is_force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0007a39b-0abb-43a8-acb8-038ae4bbbd3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T05:25:34.135475Z",
     "iopub.status.busy": "2024-01-05T05:25:34.134861Z",
     "iopub.status.idle": "2024-01-05T05:33:52.434081Z",
     "shell.execute_reply": "2024-01-05T05:33:52.432887Z",
     "shell.execute_reply.started": "2024-01-05T05:25:34.135426Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [08:15<00:00, 13.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/loss_fn.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/model.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/optimizer.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/paras.pkl exists! Use is_force=True to save it anyway\n",
      "/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/sgm_paramss_est.pkl exists! Use is_force=True to save it anyway\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_36meg_wmse/Rec_PSD.pkl\n"
     ]
    }
   ],
   "source": [
    "# calculate rec PSD and save, only need once\n",
    "sgmmodel = SGM(paras.C, paras.D, paras.freqs)\n",
    "def _run_fn(sgm_param):\n",
    "    cur_PSD = sgmmodel.run_local_coupling_forward(sgm_param)\n",
    "    return cur_PSD[:68]\n",
    "X_recs = []\n",
    "for sgm_params_est in tqdm(trained_model.sgm_paramss_est):\n",
    "    if np.sum(paras_rnn.dy_mask) == 0:\n",
    "        # only for all static model\n",
    "        X_rec = _run_fn(sgm_params_est[0])\n",
    "        X_rec = np.tile(X_rec, (len(sgm_params_est), 1, 1))\n",
    "    else:\n",
    "        with Parallel(n_jobs=20) as parallel:\n",
    "            X_rec = parallel(delayed(_run_fn)(param) for param in sgm_params_est)\n",
    "    X_recs.append(X_rec)\n",
    "    \n",
    "# save\n",
    "trained_model.Rec_PSD = np.array(X_recs)\n",
    "save_pkl_dict2folder(paras_rnn.save_dir, trained_model, is_force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f30fa4-a274-4211-b8d4-e9e8387f3f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
