{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadabb59",
   "metadata": {},
   "source": [
    "Here, I test whether my LSTM net works or not to estimate SGM parameters \n",
    "\n",
    "Now I run the real data from Parul (Apr 2, 2023)\n",
    "\n",
    "Convert to dB Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77566fcf-6190-41eb-8168-972aeea4fcad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:20:57.501501Z",
     "iopub.status.busy": "2023-05-09T20:20:57.500885Z",
     "iopub.status.idle": "2023-05-09T20:20:57.523112Z",
     "shell.execute_reply": "2023-05-09T20:20:57.521527Z",
     "shell.execute_reply.started": "2023-05-09T20:20:57.501456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_PYTHON_SCRIPT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9942dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:37:57.771920Z",
     "start_time": "2023-04-04T17:37:56.085736Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:20:57.524976Z",
     "iopub.status.busy": "2023-05-09T20:20:57.524364Z",
     "iopub.status.idle": "2023-05-09T20:20:57.895186Z",
     "shell.execute_reply": "2023-05-09T20:20:57.894108Z",
     "shell.execute_reply.started": "2023-05-09T20:20:57.524930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad09a305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:03.434191Z",
     "start_time": "2023-04-04T17:37:58.883670Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:20:57.897658Z",
     "iopub.status.busy": "2023-05-09T20:20:57.897194Z",
     "iopub.status.idle": "2023-05-09T20:20:58.918325Z",
     "shell.execute_reply": "2023-05-09T20:20:58.917219Z",
     "shell.execute_reply.started": "2023-05-09T20:20:57.897625Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import trange, tqdm\n",
    "import time\n",
    "\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fd7795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:12.476128Z",
     "start_time": "2023-04-04T17:38:04.142458Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:20:58.920859Z",
     "iopub.status.busy": "2023-05-09T20:20:58.920129Z",
     "iopub.status.idle": "2023-05-09T20:21:00.391310Z",
     "shell.execute_reply": "2023-05-09T20:21:00.390762Z",
     "shell.execute_reply.started": "2023-05-09T20:20:58.920816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.lstm' from '/data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/models/lstm.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models.lstm\n",
    "importlib.reload(models.lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0924abca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:12.656580Z",
     "start_time": "2023-04-04T17:38:12.479288Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:21:00.392712Z",
     "iopub.status.busy": "2023-05-09T20:21:00.392318Z",
     "iopub.status.idle": "2023-05-09T20:21:00.428692Z",
     "shell.execute_reply": "2023-05-09T20:21:00.427717Z",
     "shell.execute_reply.started": "2023-05-09T20:21:00.392693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.reparam import theta2raw_torch, raw2theta_torch, raw2theta_np\n",
    "from spectrome import Brain\n",
    "from sgm.sgm import SGM\n",
    "from utils.stable import paras_stable_check\n",
    "from utils.misc import save_pkl, save_pkl_dict2folder, load_pkl, load_pkl_folder2dict, delta_time\n",
    "from models.lstm import LSTM_SGM\n",
    "from models.loss import  weighted_mse_loss, reg_R_loss, lin_R_loss, lin_R_fn, reg_R_fn\n",
    "from utils.standardize import std_mat, std_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318c4ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:12.665771Z",
     "start_time": "2023-04-04T17:38:12.659314Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:21:00.430787Z",
     "iopub.status.busy": "2023-05-09T20:21:00.430117Z",
     "iopub.status.idle": "2023-05-09T20:21:00.438211Z",
     "shell.execute_reply": "2023-05-09T20:21:00.437103Z",
     "shell.execute_reply.started": "2023-05-09T20:21:00.430747Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pkgs for pytorch ( Mar 27, 2023) \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)\n",
    "    torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cd127-34b0-4132-a0a3-efa7f5c514cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7a4da6",
   "metadata": {},
   "source": [
    "# Data, fn and paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "521836de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:17.218490Z",
     "start_time": "2023-04-04T17:38:13.493691Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:24.646679Z",
     "iopub.status.busy": "2023-05-09T20:28:24.646034Z",
     "iopub.status.idle": "2023-05-09T20:28:28.740996Z",
     "shell.execute_reply": "2023-05-09T20:28:28.740493Z",
     "shell.execute_reply.started": "2023-05-09T20:28:24.646635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "fils = list(DATA_ROOT.glob(\"*s100tp.nc\")) # 300/150\n",
    "file2read = netCDF4.Dataset(fils[0], 'r')\n",
    "psd_all_full = np.array(file2read.variables[\"__xarray_dataarray_variable__\"][:])\n",
    "psd_all_full = 10 * np.log10(psd_all_full) # to dB scale\n",
    "time_points = np.array(file2read.variables[\"timepoints\"][:])\n",
    "freqs = np.array(file2read.variables[\"frequencies\"][:])\n",
    "ROIs_order = np.array(file2read.variables[\"regionx\"][:])\n",
    "file2read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "180f0d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:18.614858Z",
     "start_time": "2023-04-04T17:38:18.509968Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:28.742506Z",
     "iopub.status.busy": "2023-05-09T20:28:28.742185Z",
     "iopub.status.idle": "2023-05-09T20:28:28.787999Z",
     "shell.execute_reply": "2023-05-09T20:28:28.786932Z",
     "shell.execute_reply.started": "2023-05-09T20:28:28.742489Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Connectome\n",
    "brain = Brain.Brain()\n",
    "brain.add_connectome(DATA_ROOT)\n",
    "brain.reorder_connectome(brain.connectome, brain.distance_matrix)\n",
    "brain.bi_symmetric_c()\n",
    "brain.reduce_extreme_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f85a7c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:22.084241Z",
     "start_time": "2023-04-04T17:38:22.076317Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:28.790132Z",
     "iopub.status.busy": "2023-05-09T20:28:28.789387Z",
     "iopub.status.idle": "2023-05-09T20:28:28.798855Z",
     "shell.execute_reply": "2023-05-09T20:28:28.797887Z",
     "shell.execute_reply.started": "2023-05-09T20:28:28.790092Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some constant parameters for this file\n",
    "paras = edict()\n",
    "\n",
    "## I reorder them in an alphabetical order and I change tauC to tauG (Mar 27, 2023)\n",
    "## the orginal order is taue, taui, tauC, speed, alpha, gii, gei\n",
    "## paras.par_low = np.asarray([0.005,0.005,0.005,5, 0.1,0.001,0.001])\n",
    "## paras.par_high = np.asarray([0.03, 0.20, 0.03,20,  1,    2,  0.7])\n",
    "##\n",
    "\n",
    "# alpha, gei, gii, taue, tauG, taui, speed \n",
    "paras.par_low = np.array([0.1, 0.001,0.001, 0.005, 0.005, 0.005, 5])\n",
    "paras.par_high = np.asarray([1, 0.7, 2, 0.03, 0.03, 0.20, 20])\n",
    "paras.prior_bds = np.array([paras.par_low, paras.par_high]).T\n",
    "paras.names = [\"alpha\", \"gei\", \"gii\", \"Taue\", \"TauG\", \"Taui\", \"Speed\"]\n",
    "\n",
    "paras.C = brain.reducedConnectome\n",
    "paras.D = brain.distance_matrix\n",
    "paras.freqs = freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ce16ba",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49a3544-8248-45e0-b006-4464dbaaf09f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:36.267294Z",
     "start_time": "2023-04-04T17:38:35.514912Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:28.801508Z",
     "iopub.status.busy": "2023-05-09T20:28:28.800750Z",
     "iopub.status.idle": "2023-05-09T20:28:29.564890Z",
     "shell.execute_reply": "2023-05-09T20:28:29.563774Z",
     "shell.execute_reply.started": "2023-05-09T20:28:28.801447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net_large/freqs.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net_large/loss.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net_large/loss_test.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net_large/model.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/SGM_net_large/paras.pkl\n"
     ]
    }
   ],
   "source": [
    "trained_model = load_pkl_folder2dict(RES_ROOT/\"SGM_net_large\", excluding=['opt*'])\n",
    "sgm_net = trained_model.model;\n",
    "sgm_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fe17f7e-27c4-46fb-8c28-37e34b229746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:31.390933Z",
     "iopub.status.busy": "2023-05-09T20:28:31.390296Z",
     "iopub.status.idle": "2023-05-09T20:28:32.305855Z",
     "shell.execute_reply": "2023-05-09T20:28:32.305281Z",
     "shell.execute_reply.started": "2023-05-09T20:28:31.390887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not RUN_PYTHON_SCRIPT:\n",
    "    plt.plot(np.array(trained_model.loss)/10)\n",
    "    plt.plot(trained_model.loss_test)\n",
    "    #plt.xticks(np.arange(0, 120, 14));\n",
    "    plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d507dc44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:38:47.060338Z",
     "start_time": "2023-04-04T17:38:46.969000Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:40.062909Z",
     "iopub.status.busy": "2023-05-09T20:28:40.062144Z",
     "iopub.status.idle": "2023-05-09T20:28:40.080747Z",
     "shell.execute_reply": "2023-05-09T20:28:40.079650Z",
     "shell.execute_reply.started": "2023-05-09T20:28:40.062865Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to generate training sample (Apr 1, 2023)\n",
    "def random_choice(n, batchsize=1, len_seg=None):\n",
    "    \"\"\"Randomly select the lower and upper bound of the segment\n",
    "        args:\n",
    "            n: len of the total time series\n",
    "    \"\"\"\n",
    "    if len_seg is None:\n",
    "        len_seg = torch.randint(low=10, high=100, size=(1, ))\n",
    "    up_bd = torch.randint(low=len_seg.item(), high=n, size=(batchsize, ))\n",
    "    low_bd = up_bd - len_seg\n",
    "    return low_bd, up_bd\n",
    "\n",
    "\n",
    "def random_samples_rnn(X, Y=None, batchsize=1, \n",
    "                       bds=None, \n",
    "                       is_std=True, \n",
    "                       theta2raw_fn=None):\n",
    "    \"\"\"Randomly select a sample from the whole segment\n",
    "        args:\n",
    "            X: PSD, num_seq x 68 x nfreq or \n",
    "               PSD, num_sub x num_seq x 68 x nfreq\n",
    "            Y: params, num x 7, in original sgm scale\n",
    "        return:\n",
    "            X_seqs: len_seq x batchsize x num_fs\n",
    "            Y_seqs: len_seq x batchsize x 7\n",
    "            \n",
    "    \"\"\"\n",
    "    if X.ndim == 4:\n",
    "        # if multiple subjects, pick up a subject\n",
    "        num_sub = X.shape[0]\n",
    "        sub_idx = np.random.randint(low=0, high=num_sub)\n",
    "        X = X[sub_idx]\n",
    "        \n",
    "    if not isinstance(X, torch.Tensor):\n",
    "        X = torch.tensor(X)\n",
    "    if is_std:\n",
    "        #X = X/X.std(axis=(1, 2), keepdims=True)\n",
    "        # Let std for each ROI and each data\n",
    "        X = (X-X.mean(axis=2, keepdims=True))/X.std(axis=2, keepdims=True)\n",
    "    if Y is not None:\n",
    "        if not isinstance(Y, torch.Tensor):\n",
    "            Y = torch.tensor(Y)\n",
    "        if theta2raw_fn: \n",
    "            Y = theta2raw_fn(Y)\n",
    "    if bds is None:\n",
    "        low_bds, up_bds = random_choice(len(X), batchsize)\n",
    "    else:\n",
    "        low_bds, up_bds = bds\n",
    "\n",
    "    X = X.flatten(1)\n",
    "    X_seqs = []\n",
    "    Y_seqs = []\n",
    "    for low_bd, up_bd in zip(low_bds, up_bds):\n",
    "        X_seq = X[low_bd:up_bd, :].unsqueeze(1)\n",
    "        X_seqs.append(X_seq)\n",
    "        if Y is not None:\n",
    "            Y_seq = Y[low_bd:up_bd].unsqueeze(1)\n",
    "            Y_seqs.append(Y_seq)\n",
    "    if Y is not None:\n",
    "        return torch.cat(X_seqs, dim=1), torch.cat(Y_seqs, dim=1)\n",
    "    else:\n",
    "        return torch.cat(X_seqs, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2db4078d-5415-4185-9076-db8bdcff80db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:40.530174Z",
     "iopub.status.busy": "2023-05-09T20:28:40.529554Z",
     "iopub.status.idle": "2023-05-09T20:28:40.540580Z",
     "shell.execute_reply": "2023-05-09T20:28:40.539064Z",
     "shell.execute_reply.started": "2023-05-09T20:28:40.530119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(all_data):\n",
    "    num_sub, len_seq, _, _ = all_data.shape\n",
    "    all_data_raw = torch.tensor(all_data).transpose(1, 0)\n",
    "    all_data_input = (all_data_raw - all_data_raw.mean(axis=-1, keepdims=True))/all_data_raw.std(axis=-1, keepdims=True);\n",
    "    all_data_input = all_data_input.flatten(2);\n",
    "    \n",
    "    Y_pred = rnn(all_data_input);\n",
    "    X_pred = sgm_net(Y_pred.flatten(0, 1));\n",
    "    corrs = reg_R_fn(all_data_raw.flatten(0, 1), X_pred);\n",
    "    corrs = corrs.reshape(len_seq, num_sub, -1).transpose(1, 0)\n",
    "    return corrs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ace453aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T19:25:30.343060Z",
     "start_time": "2023-04-04T19:25:30.335835Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:41.117381Z",
     "iopub.status.busy": "2023-05-09T20:28:41.116692Z",
     "iopub.status.idle": "2023-05-09T20:28:41.825778Z",
     "shell.execute_reply": "2023-05-09T20:28:41.825095Z",
     "shell.execute_reply.started": "2023-05-09T20:28:41.117338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paras_rnn = edict()\n",
    "paras_rnn.batchsize = 128\n",
    "paras_rnn.niter = 500\n",
    "paras_rnn.loss_out = 5\n",
    "paras_rnn.eval_out = 20\n",
    "paras_rnn.clip = 1 # from \n",
    "paras_rnn.lr_step = 10\n",
    "\n",
    "paras_rnn.k = 1\n",
    "paras_rnn.hidden_dim = int(1024/1)\n",
    "paras_rnn.output_dim = 7\n",
    "paras_rnn.input_dim = 68*len(paras.freqs)\n",
    "paras_rnn.is_bidirectional = False\n",
    "paras_rnn.unstable_pen = 10000 # Whether to filter out the unstable sps or not, if 0 not, if large number, yes\n",
    "paras_rnn.loss_name = \"corr\" # linR, corr, wmse or mse\n",
    "#paras.names = [\"alpha\", \"gei\", \"gii\", \"Taue\", \"TauG\", \"Taui\", \"Speed\"]\n",
    "# 1 dynamic, 0 static\n",
    "paras_rnn.dy_mask = [0, 0, 0, 0, 0, 0, 0] \n",
    "\n",
    "# delete a sig outlier\n",
    "psd_all = psd_all_full\n",
    "#psd_all = np.delete(psd_all_full, 24, axis=-1)\n",
    "#  real data, should be len_seq x nrois x nfreqs\n",
    "data_idx = 0\n",
    "cur_data = psd_all[:, :, :, 1].transpose(2, 0, 1)\n",
    "#  real data, should be num_sub x len_seq x nrois x nfreqs\n",
    "all_data = psd_all.transpose(3, 2, 0, 1);\n",
    "\n",
    "all_data_raw = torch.tensor(all_data).transpose(1, 0)\n",
    "all_data_input = (all_data_raw - all_data_raw.mean(axis=-1, keepdims=True))/all_data_raw.std(axis=-1, keepdims=True);\n",
    "all_data_input = all_data_input.flatten(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b8b59c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T20:27:57.475018Z",
     "start_time": "2023-04-04T20:27:57.334374Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:41.878137Z",
     "iopub.status.busy": "2023-05-09T20:28:41.877825Z",
     "iopub.status.idle": "2023-05-09T20:28:42.147087Z",
     "shell.execute_reply": "2023-05-09T20:28:42.146194Z",
     "shell.execute_reply.started": "2023-05-09T20:28:41.878118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.ExponentialLR at 0x7fe195672cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = LSTM_SGM(input_dim=paras_rnn.input_dim, \n",
    "               hidden_dim=paras_rnn.hidden_dim, \n",
    "               output_dim=paras_rnn.output_dim, \n",
    "               is_bidirectional=paras_rnn.is_bidirectional, \n",
    "               prior_bds=torch.tensor(paras.prior_bds), \n",
    "               k = paras_rnn.k, \n",
    "               dy_mask = paras_rnn.dy_mask\n",
    ")\n",
    "if paras_rnn.loss_name.startswith(\"corr\"):\n",
    "    loss_fn = reg_R_loss\n",
    "elif paras_rnn.loss_name.startswith(\"linR\"):\n",
    "    loss_fn = lin_R_loss\n",
    "elif paras_rnn.loss_name.startswith(\"wmse\"):\n",
    "    loss_fn = weighted_mse_loss\n",
    "elif paras_rnn.loss_name.startswith(\"mse\"):\n",
    "    loss_fn = nn.MSELoss()\n",
    "else:\n",
    "    raise KeyError(\"No such loss\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnn.parameters(), lr=2e-4, weight_decay=0)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16653792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T20:39:31.112388Z",
     "start_time": "2023-04-04T20:27:58.069870Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T17:49:37.935234Z",
     "iopub.status.busy": "2023-05-09T17:49:37.934600Z",
     "iopub.status.idle": "2023-05-09T18:50:11.508443Z",
     "shell.execute_reply": "2023-05-09T18:50:11.493413Z",
     "shell.execute_reply.started": "2023-05-09T17:49:37.935188Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iter 5/500, the losses are -0.80260 (train). The time used is 40.114s. \n",
      "Adjusting learning rate of group 0 to 1.8000e-04.\n",
      "At iter 10/500, the losses are -0.82354 (train). The time used is 34.317s. \n",
      "At iter 15/500, the losses are -0.82914 (train). The time used is 33.414s. \n",
      "Adjusting learning rate of group 0 to 1.6200e-04.\n",
      "At iter 20/500, the losses are -0.83048 (train). The time used is 32.845s. \n",
      "====================================================================================================\n",
      "At iter 20/500, the losses on all data are 0.83066. The time used is 1.975s. \n",
      "====================================================================================================\n",
      "At iter 25/500, the losses are -0.83122 (train). The time used is 35.026s. \n",
      "Adjusting learning rate of group 0 to 1.4580e-04.\n",
      "At iter 30/500, the losses are -0.83201 (train). The time used is 34.494s. \n",
      "At iter 35/500, the losses are -0.83233 (train). The time used is 35.129s. \n",
      "Adjusting learning rate of group 0 to 1.3122e-04.\n",
      "At iter 40/500, the losses are -0.83254 (train). The time used is 34.393s. \n",
      "====================================================================================================\n",
      "At iter 40/500, the losses on all data are 0.83265. The time used is 2.403s. \n",
      "====================================================================================================\n",
      "At iter 45/500, the losses are -0.83269 (train). The time used is 36.646s. \n",
      "Adjusting learning rate of group 0 to 1.1810e-04.\n",
      "At iter 50/500, the losses are -0.83287 (train). The time used is 34.916s. \n",
      "At iter 55/500, the losses are -0.83300 (train). The time used is 36.104s. \n",
      "Adjusting learning rate of group 0 to 1.0629e-04.\n",
      "At iter 60/500, the losses are -0.83314 (train). The time used is 33.734s. \n",
      "====================================================================================================\n",
      "At iter 60/500, the losses on all data are 0.83323. The time used is 2.351s. \n",
      "====================================================================================================\n",
      "At iter 65/500, the losses are -0.83328 (train). The time used is 33.749s. \n",
      "Adjusting learning rate of group 0 to 9.5659e-05.\n",
      "At iter 70/500, the losses are -0.83339 (train). The time used is 32.163s. \n",
      "At iter 75/500, the losses are -0.83350 (train). The time used is 33.852s. \n",
      "Adjusting learning rate of group 0 to 8.6093e-05.\n",
      "At iter 80/500, the losses are -0.83360 (train). The time used is 35.047s. \n",
      "====================================================================================================\n",
      "At iter 80/500, the losses on all data are 0.83366. The time used is 2.403s. \n",
      "====================================================================================================\n",
      "At iter 85/500, the losses are -0.83370 (train). The time used is 36.435s. \n",
      "Adjusting learning rate of group 0 to 7.7484e-05.\n",
      "At iter 90/500, the losses are -0.83379 (train). The time used is 36.213s. \n",
      "At iter 95/500, the losses are -0.83387 (train). The time used is 35.476s. \n",
      "Adjusting learning rate of group 0 to 6.9736e-05.\n",
      "At iter 100/500, the losses are -0.83394 (train). The time used is 37.138s. \n",
      "====================================================================================================\n",
      "At iter 100/500, the losses on all data are 0.83398. The time used is 2.361s. \n",
      "====================================================================================================\n",
      "At iter 105/500, the losses are -0.83400 (train). The time used is 35.454s. \n",
      "Adjusting learning rate of group 0 to 6.2762e-05.\n",
      "At iter 110/500, the losses are -0.83405 (train). The time used is 35.029s. \n",
      "At iter 115/500, the losses are -0.83410 (train). The time used is 34.061s. \n",
      "Adjusting learning rate of group 0 to 5.6486e-05.\n",
      "At iter 120/500, the losses are -0.83415 (train). The time used is 36.290s. \n",
      "====================================================================================================\n",
      "At iter 120/500, the losses on all data are 0.83417. The time used is 2.385s. \n",
      "====================================================================================================\n",
      "At iter 125/500, the losses are -0.83419 (train). The time used is 34.956s. \n",
      "Adjusting learning rate of group 0 to 5.0837e-05.\n",
      "At iter 130/500, the losses are -0.83423 (train). The time used is 36.863s. \n",
      "At iter 135/500, the losses are -0.83427 (train). The time used is 31.716s. \n",
      "Adjusting learning rate of group 0 to 4.5754e-05.\n",
      "At iter 140/500, the losses are -0.83430 (train). The time used is 35.121s. \n",
      "====================================================================================================\n",
      "At iter 140/500, the losses on all data are 0.83432. The time used is 2.460s. \n",
      "====================================================================================================\n",
      "At iter 145/500, the losses are -0.83434 (train). The time used is 37.694s. \n",
      "Adjusting learning rate of group 0 to 4.1178e-05.\n",
      "At iter 150/500, the losses are -0.83437 (train). The time used is 32.765s. \n",
      "At iter 155/500, the losses are -0.83439 (train). The time used is 36.853s. \n",
      "Adjusting learning rate of group 0 to 3.7060e-05.\n",
      "At iter 160/500, the losses are -0.83442 (train). The time used is 36.787s. \n",
      "====================================================================================================\n",
      "At iter 160/500, the losses on all data are 0.83444. The time used is 2.451s. \n",
      "====================================================================================================\n",
      "At iter 165/500, the losses are -0.83445 (train). The time used is 35.363s. \n",
      "Adjusting learning rate of group 0 to 3.3354e-05.\n",
      "At iter 170/500, the losses are -0.83447 (train). The time used is 35.276s. \n",
      "At iter 175/500, the losses are -0.83449 (train). The time used is 36.170s. \n",
      "Adjusting learning rate of group 0 to 3.0019e-05.\n",
      "At iter 180/500, the losses are -0.83451 (train). The time used is 35.662s. \n",
      "====================================================================================================\n",
      "At iter 180/500, the losses on all data are 0.83452. The time used is 2.437s. \n",
      "====================================================================================================\n",
      "At iter 185/500, the losses are -0.83453 (train). The time used is 34.162s. \n",
      "Adjusting learning rate of group 0 to 2.7017e-05.\n",
      "At iter 190/500, the losses are -0.83456 (train). The time used is 32.722s. \n",
      "At iter 195/500, the losses are -0.83459 (train). The time used is 34.840s. \n",
      "Adjusting learning rate of group 0 to 2.4315e-05.\n",
      "At iter 200/500, the losses are -0.83461 (train). The time used is 32.854s. \n",
      "====================================================================================================\n",
      "At iter 200/500, the losses on all data are 0.83463. The time used is 1.783s. \n",
      "====================================================================================================\n",
      "At iter 205/500, the losses are -0.83464 (train). The time used is 36.304s. \n",
      "Adjusting learning rate of group 0 to 2.1884e-05.\n",
      "At iter 210/500, the losses are -0.83466 (train). The time used is 36.702s. \n",
      "At iter 215/500, the losses are -0.83468 (train). The time used is 35.346s. \n",
      "Adjusting learning rate of group 0 to 1.9695e-05.\n",
      "At iter 220/500, the losses are -0.83470 (train). The time used is 37.148s. \n",
      "====================================================================================================\n",
      "At iter 220/500, the losses on all data are 0.83472. The time used is 2.222s. \n",
      "====================================================================================================\n",
      "At iter 225/500, the losses are -0.83472 (train). The time used is 33.925s. \n",
      "Adjusting learning rate of group 0 to 1.7726e-05.\n",
      "At iter 230/500, the losses are -0.83474 (train). The time used is 35.377s. \n",
      "At iter 235/500, the losses are -0.83475 (train). The time used is 35.120s. \n",
      "Adjusting learning rate of group 0 to 1.5953e-05.\n",
      "At iter 240/500, the losses are -0.83477 (train). The time used is 34.320s. \n",
      "====================================================================================================\n",
      "At iter 240/500, the losses on all data are 0.83477. The time used is 2.275s. \n",
      "====================================================================================================\n",
      "At iter 245/500, the losses are -0.83478 (train). The time used is 34.488s. \n",
      "Adjusting learning rate of group 0 to 1.4358e-05.\n",
      "At iter 250/500, the losses are -0.83479 (train). The time used is 36.039s. \n",
      "At iter 255/500, the losses are -0.83480 (train). The time used is 38.201s. \n",
      "Adjusting learning rate of group 0 to 1.2922e-05.\n",
      "At iter 260/500, the losses are -0.83481 (train). The time used is 36.306s. \n",
      "====================================================================================================\n",
      "At iter 260/500, the losses on all data are 0.83482. The time used is 2.316s. \n",
      "====================================================================================================\n",
      "At iter 265/500, the losses are -0.83482 (train). The time used is 36.511s. \n",
      "Adjusting learning rate of group 0 to 1.1630e-05.\n",
      "At iter 270/500, the losses are -0.83483 (train). The time used is 36.036s. \n",
      "At iter 275/500, the losses are -0.83484 (train). The time used is 36.246s. \n",
      "Adjusting learning rate of group 0 to 1.0467e-05.\n",
      "At iter 280/500, the losses are -0.83485 (train). The time used is 35.054s. \n",
      "====================================================================================================\n",
      "At iter 280/500, the losses on all data are 0.83485. The time used is 2.502s. \n",
      "====================================================================================================\n",
      "At iter 285/500, the losses are -0.83485 (train). The time used is 39.325s. \n",
      "Adjusting learning rate of group 0 to 9.4203e-06.\n",
      "At iter 290/500, the losses are -0.83486 (train). The time used is 33.612s. \n",
      "At iter 295/500, the losses are -0.83487 (train). The time used is 33.042s. \n",
      "Adjusting learning rate of group 0 to 8.4782e-06.\n",
      "At iter 300/500, the losses are -0.83487 (train). The time used is 34.640s. \n",
      "====================================================================================================\n",
      "At iter 300/500, the losses on all data are 0.83487. The time used is 2.378s. \n",
      "====================================================================================================\n",
      "At iter 305/500, the losses are -0.83488 (train). The time used is 35.719s. \n",
      "Adjusting learning rate of group 0 to 7.6304e-06.\n",
      "At iter 310/500, the losses are -0.83488 (train). The time used is 36.905s. \n",
      "At iter 315/500, the losses are -0.83488 (train). The time used is 37.381s. \n",
      "Adjusting learning rate of group 0 to 6.8674e-06.\n",
      "At iter 320/500, the losses are -0.83489 (train). The time used is 36.275s. \n",
      "====================================================================================================\n",
      "At iter 320/500, the losses on all data are 0.83489. The time used is 1.965s. \n",
      "====================================================================================================\n",
      "At iter 325/500, the losses are -0.83489 (train). The time used is 38.168s. \n",
      "Adjusting learning rate of group 0 to 6.1806e-06.\n",
      "At iter 330/500, the losses are -0.83490 (train). The time used is 39.389s. \n",
      "At iter 335/500, the losses are -0.83490 (train). The time used is 34.976s. \n",
      "Adjusting learning rate of group 0 to 5.5626e-06.\n",
      "At iter 340/500, the losses are -0.83490 (train). The time used is 37.089s. \n",
      "====================================================================================================\n",
      "At iter 340/500, the losses on all data are 0.83490. The time used is 2.422s. \n",
      "====================================================================================================\n",
      "At iter 345/500, the losses are -0.83490 (train). The time used is 35.533s. \n",
      "Adjusting learning rate of group 0 to 5.0063e-06.\n",
      "At iter 350/500, the losses are -0.83491 (train). The time used is 37.450s. \n",
      "At iter 355/500, the losses are -0.83491 (train). The time used is 36.222s. \n",
      "Adjusting learning rate of group 0 to 4.5057e-06.\n",
      "At iter 360/500, the losses are -0.83491 (train). The time used is 35.702s. \n",
      "====================================================================================================\n",
      "At iter 360/500, the losses on all data are 0.83491. The time used is 2.391s. \n",
      "====================================================================================================\n",
      "At iter 365/500, the losses are -0.83491 (train). The time used is 34.703s. \n",
      "Adjusting learning rate of group 0 to 4.0551e-06.\n",
      "At iter 370/500, the losses are -0.83492 (train). The time used is 35.512s. \n",
      "At iter 375/500, the losses are -0.83492 (train). The time used is 33.536s. \n",
      "Adjusting learning rate of group 0 to 3.6496e-06.\n",
      "At iter 380/500, the losses are -0.83492 (train). The time used is 34.791s. \n",
      "====================================================================================================\n",
      "At iter 380/500, the losses on all data are 0.83492. The time used is 2.442s. \n",
      "====================================================================================================\n",
      "At iter 385/500, the losses are -0.83492 (train). The time used is 34.861s. \n",
      "Adjusting learning rate of group 0 to 3.2846e-06.\n",
      "At iter 390/500, the losses are -0.83492 (train). The time used is 32.846s. \n",
      "At iter 395/500, the losses are -0.83493 (train). The time used is 36.397s. \n",
      "Adjusting learning rate of group 0 to 2.9562e-06.\n",
      "At iter 400/500, the losses are -0.83493 (train). The time used is 36.807s. \n",
      "====================================================================================================\n",
      "At iter 400/500, the losses on all data are 0.83493. The time used is 2.496s. \n",
      "====================================================================================================\n",
      "At iter 405/500, the losses are -0.83493 (train). The time used is 36.420s. \n",
      "Adjusting learning rate of group 0 to 2.6606e-06.\n",
      "At iter 410/500, the losses are -0.83493 (train). The time used is 34.830s. \n",
      "At iter 415/500, the losses are -0.83493 (train). The time used is 36.628s. \n",
      "Adjusting learning rate of group 0 to 2.3945e-06.\n",
      "At iter 420/500, the losses are -0.83493 (train). The time used is 36.688s. \n",
      "====================================================================================================\n",
      "At iter 420/500, the losses on all data are 0.83493. The time used is 2.365s. \n",
      "====================================================================================================\n",
      "At iter 425/500, the losses are -0.83493 (train). The time used is 36.100s. \n",
      "Adjusting learning rate of group 0 to 2.1551e-06.\n",
      "At iter 430/500, the losses are -0.83494 (train). The time used is 35.436s. \n",
      "At iter 435/500, the losses are -0.83494 (train). The time used is 35.237s. \n",
      "Adjusting learning rate of group 0 to 1.9395e-06.\n",
      "At iter 440/500, the losses are -0.83494 (train). The time used is 35.675s. \n",
      "====================================================================================================\n",
      "At iter 440/500, the losses on all data are 0.83494. The time used is 2.335s. \n",
      "====================================================================================================\n",
      "At iter 445/500, the losses are -0.83494 (train). The time used is 35.018s. \n",
      "Adjusting learning rate of group 0 to 1.7456e-06.\n",
      "At iter 450/500, the losses are -0.83494 (train). The time used is 33.768s. \n",
      "At iter 455/500, the losses are -0.83494 (train). The time used is 37.823s. \n",
      "Adjusting learning rate of group 0 to 1.5710e-06.\n",
      "At iter 460/500, the losses are -0.83494 (train). The time used is 40.206s. \n",
      "====================================================================================================\n",
      "At iter 460/500, the losses on all data are 0.83494. The time used is 2.227s. \n",
      "====================================================================================================\n",
      "At iter 465/500, the losses are -0.83494 (train). The time used is 37.907s. \n",
      "Adjusting learning rate of group 0 to 1.4139e-06.\n",
      "At iter 470/500, the losses are -0.83494 (train). The time used is 37.145s. \n",
      "At iter 475/500, the losses are -0.83494 (train). The time used is 44.591s. \n",
      "Adjusting learning rate of group 0 to 1.2725e-06.\n",
      "At iter 480/500, the losses are -0.83494 (train). The time used is 37.623s. \n",
      "====================================================================================================\n",
      "At iter 480/500, the losses on all data are 0.83494. The time used is 3.863s. \n",
      "====================================================================================================\n",
      "At iter 485/500, the losses are -0.83494 (train). The time used is 36.900s. \n",
      "Adjusting learning rate of group 0 to 1.1453e-06.\n",
      "At iter 490/500, the losses are -0.83495 (train). The time used is 37.169s. \n",
      "At iter 495/500, the losses are -0.83495 (train). The time used is 36.565s. \n",
      "Adjusting learning rate of group 0 to 1.0308e-06.\n",
      "At iter 500/500, the losses are -0.83495 (train). The time used is 36.321s. \n",
      "====================================================================================================\n",
      "At iter 500/500, the losses on all data are 0.83495. The time used is 2.294s. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_cur = 0\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "t0 = time.time()\n",
    "sgm_net.eval()\n",
    "loss_add = 0\n",
    "for ix in range(paras_rnn.niter):\n",
    "    rnn.train()\n",
    "    #X_seq = random_samples_rnn(all_data[24], \n",
    "    #                           batchsize=paras_rnn.batchsize)\n",
    "    X_seq = all_data_input\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    theta_pred = rnn(X_seq)\n",
    "    X_pred = sgm_net(theta_pred.flatten(0, 1))\n",
    "    loss_main = loss_fn(X_seq.flatten(0, 1).reshape(-1, 68, len(paras.freqs)),\n",
    "                   X_pred)\n",
    "    if paras_rnn.unstable_pen > 0:\n",
    "        unstable_inds = paras_stable_check(theta_pred.flatten(0, 1).detach().numpy());\n",
    "        unstable_inds = torch.tensor(unstable_inds).reshape(*theta_pred.shape[:2])\n",
    "        loss_add = (paras_rnn.unstable_pen * unstable_inds.unsqueeze(-1) * theta_pred).mean();\n",
    "    loss = loss_main + loss_add\n",
    "    \n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), paras_rnn.clip)\n",
    "    # Perform optimization\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ix % paras_rnn.lr_step == (paras_rnn.lr_step-1):\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss_cur = loss_cur + loss_main.item()\n",
    "    if ix % paras_rnn.loss_out == (paras_rnn.loss_out-1):\n",
    "        losses.append(loss_cur/paras_rnn.loss_out)\n",
    "        print(f\"At iter {ix+1}/{paras_rnn.niter}, \"\n",
    "              f\"the losses are {loss_cur/paras_rnn.loss_out:.5f} (train). \"\n",
    "              f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "             )\n",
    "        loss_cur = 0\n",
    "        t0 = time.time()\n",
    "        \n",
    "    if ix % paras_rnn.eval_out == (paras_rnn.eval_out-1):\n",
    "        rnn.eval()\n",
    "        loss_test = evaluate(all_data).mean()\n",
    "        losses_test.append(loss_test)\n",
    "        print(f\"=\"*100)\n",
    "        print(f\"At iter {ix+1}/{paras_rnn.niter}, \"\n",
    "              f\"the losses on all data are {loss_test:.5f}. \"\n",
    "              f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "             )\n",
    "        print(f\"=\"*100)\n",
    "        t0 = time.time()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "041b9d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T20:55:50.277877Z",
     "start_time": "2023-04-04T20:55:50.180639Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T18:50:11.565491Z",
     "iopub.status.busy": "2023-05-09T18:50:11.564960Z",
     "iopub.status.idle": "2023-05-09T18:50:12.400844Z",
     "shell.execute_reply": "2023-05-09T18:50:12.399454Z",
     "shell.execute_reply.started": "2023-05-09T18:50:11.565463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not RUN_PYTHON_SCRIPT:\n",
    "    plt.plot(losses[:])\n",
    "    #plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1147e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef8fc65",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e11d6603-bb35-4621-8d20-25265af5685e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:28:49.256044Z",
     "iopub.status.busy": "2023-05-09T20:28:49.255404Z",
     "iopub.status.idle": "2023-05-09T20:28:49.267747Z",
     "shell.execute_reply": "2023-05-09T20:28:49.266709Z",
     "shell.execute_reply.started": "2023-05-09T20:28:49.255999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_part = \"_\".join(np.array(paras.names)[np.array(paras_rnn.dy_mask)==0][:-1])\n",
    "folder_name = f\"LSTM_simu_net_{paras_rnn.loss_name}_{dy_part}\";\n",
    "folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8865f4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T20:56:01.835052Z",
     "start_time": "2023-04-04T20:55:55.813367Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-09T20:36:28.795851Z",
     "iopub.status.busy": "2023-05-09T20:36:28.795211Z",
     "iopub.status.idle": "2023-05-09T20:36:34.647855Z",
     "shell.execute_reply": "2023-05-09T20:36:34.605687Z",
     "shell.execute_reply.started": "2023-05-09T20:36:28.795807Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/loss.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/loss_fn.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/model.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/optimizer.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/paras.pkl\n",
      "Load file /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/sgm_paramss_est.pkl\n"
     ]
    }
   ],
   "source": [
    "if (RES_ROOT/folder_name).exists():\n",
    "    trained_model = load_pkl_folder2dict(RES_ROOT/folder_name)\n",
    "else:\n",
    "    trained_model = edict()\n",
    "    trained_model.model = rnn\n",
    "    trained_model.loss_fn = loss_fn\n",
    "    trained_model.optimizer = optimizer\n",
    "    trained_model.paras = paras_rnn\n",
    "    trained_model.loss = losses\n",
    "    save_pkl_dict2folder(RES_ROOT/folder_name, trained_model, is_force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95b8d8-ed67-42b4-baac-8448f6cb203f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a978aa-d304-4743-871a-7c56d5e0a3e6",
   "metadata": {},
   "source": [
    "# PSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06ca1333-81c2-4dfe-a619-c749f077704a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:36:58.724931Z",
     "iopub.status.busy": "2023-05-09T20:36:58.724138Z",
     "iopub.status.idle": "2023-05-09T20:37:22.635050Z",
     "shell.execute_reply": "2023-05-09T20:37:22.633622Z",
     "shell.execute_reply.started": "2023-05-09T20:36:58.724881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:07<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/loss.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/loss_fn.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/model.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/optimizer.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/paras.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/TV-SGM/notebooks/../mypkg/../results/LSTM_simu_net_corr_alpha_gei_gii_Taue_TauG_Taui/sgm_paramss_est.pkl\n"
     ]
    }
   ],
   "source": [
    "trained_model.model.eval()\n",
    "sgm_paramss_est = []\n",
    "for data_idx  in trange(36):\n",
    "    cur_data = psd_all[:, :, :, data_idx].transpose(2, 0, 1)\n",
    "    X_test = random_samples_rnn(cur_data,\n",
    "                                bds=[[0], [360]],\n",
    "                                theta2raw_fn=None)\n",
    "    with torch.no_grad():\n",
    "        Y_pred = trained_model.model(X_test).squeeze()\n",
    "        sgm_paramss_est.append(Y_pred.numpy())\n",
    "sgm_paramss_est = np.array(sgm_paramss_est);\n",
    "\n",
    "trained_model.sgm_paramss_est = sgm_paramss_est\n",
    "save_pkl_dict2folder(RES_ROOT/folder_name, trained_model, is_force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88d8ec8c-4960-4d7d-b038-2579796ccd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T20:38:14.819993Z",
     "iopub.status.busy": "2023-05-09T20:38:14.819350Z",
     "iopub.status.idle": "2023-05-09T20:38:14.843788Z",
     "shell.execute_reply": "2023-05-09T20:38:14.842370Z",
     "shell.execute_reply.started": "2023-05-09T20:38:14.819945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate rec PSD and save, only need once\n",
    "# only for all static model\n",
    "if False:\n",
    "    sgmmodel = SGM(paras.C, paras.D, paras.freqs)\n",
    "    def fn(sgm_param):\n",
    "        cur_PSD = sgmmodel.run_local_coupling_forward(sgm_param)\n",
    "        return cur_PSD[:68]\n",
    "        \n",
    "    X_recs = []\n",
    "    for sgm_params_est in tqdm(trained_model.sgm_paramss_est, total=36):\n",
    "        X_rec = fn(sgm_params_est[0])\n",
    "        X_rec = np.tile(X_rec, (len(sgm_params_est), 1, 1))\n",
    "        X_recs.append(X_rec)\n",
    "    # save\n",
    "    trained_model.Rec_PSD = np.array(X_recs)\n",
    "    save_pkl_dict2folder(RES_ROOT/folder_name, trained_model, is_force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b240252-8bd6-4aab-ac90-a802c8f421de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T18:50:34.960681Z",
     "iopub.status.busy": "2023-05-09T18:50:34.959773Z",
     "iopub.status.idle": "2023-05-09T19:35:21.673196Z",
     "shell.execute_reply": "2023-05-09T19:35:21.670059Z",
     "shell.execute_reply.started": "2023-05-09T18:50:34.960633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate rec PSD and save, only need once\n",
    "import multiprocessing as mp\n",
    "num_core = 20\n",
    "\n",
    "sgmmodel = SGM(paras.C, paras.D, paras.freqs)\n",
    "def fn(sgm_param):\n",
    "    cur_PSD = sgmmodel.run_local_coupling_forward(sgm_param)\n",
    "    return cur_PSD[:68]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    X_recs = []\n",
    "    for sgm_params_est in sgm_paramss_est:\n",
    "        with mp.Pool(num_core) as pool:\n",
    "            all_procs = pool.imap(fn, sgm_params_est)\n",
    "            X_rec = list(tqdm(all_procs, total=len(sgm_params_est)))\n",
    "        X_recs.append(X_rec)\n",
    "# save\n",
    "trained_model.Rec_PSD = np.array(X_recs)\n",
    "save_pkl_dict2folder(RES_ROOT/folder_name, trained_model, is_force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ff2fb-e467-4a8f-b576-01905f2cb496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
